{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e06bc3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making changes to tempdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e19c121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a working pipeline that you can apply and get a viz for every ten seconds.\n",
    "\n",
    "# refactor readfilerun to take in code properly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4eb17fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import sys\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from os import listdir\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.datasets import make_hastie_10_2\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import warnings\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dbd6c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, 'src')\n",
    "from helper import *\n",
    "from eda import *\n",
    "from train import *\n",
    "from etl import *\n",
    "\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf1b6dd",
   "metadata": {},
   "source": [
    "### etl (new readfilerun and gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0d20b08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1643685509.5692217"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af20238f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>IP1</th>\n",
       "      <th>Port1</th>\n",
       "      <th>IP2</th>\n",
       "      <th>Port2</th>\n",
       "      <th>Proto</th>\n",
       "      <th>1-&gt;2Bytes</th>\n",
       "      <th>2-&gt;1Bytes</th>\n",
       "      <th>1-&gt;2Pkts</th>\n",
       "      <th>2-&gt;1Pkts</th>\n",
       "      <th>packet_times</th>\n",
       "      <th>packet_sizes</th>\n",
       "      <th>packet_dirs</th>\n",
       "      <th>event</th>\n",
       "      <th>drop_unix</th>\n",
       "      <th>latency</th>\n",
       "      <th>loss</th>\n",
       "      <th>later_latency</th>\n",
       "      <th>later_loss</th>\n",
       "      <th>deterministic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1642571669</td>\n",
       "      <td>172.20.0.3</td>\n",
       "      <td>42438</td>\n",
       "      <td>172.18.0.2</td>\n",
       "      <td>5001</td>\n",
       "      <td>6</td>\n",
       "      <td>13664</td>\n",
       "      <td>60</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1642571669998;1642571669998;1642571669998;1642...</td>\n",
       "      <td>60;52;112;1500;1500;1500;1500;1500;1500;1500;1...</td>\n",
       "      <td>2;1;1;1;1;1;1;1;1;1;1;1;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300</td>\n",
       "      <td>5000</td>\n",
       "      <td>300</td>\n",
       "      <td>500</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1642571670</td>\n",
       "      <td>172.20.0.3</td>\n",
       "      <td>42438</td>\n",
       "      <td>172.18.0.2</td>\n",
       "      <td>5001</td>\n",
       "      <td>6</td>\n",
       "      <td>30000</td>\n",
       "      <td>520</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>1642571670600;1642571670600;1642571670600;1642...</td>\n",
       "      <td>52;1500;1500;52;1500;1500;52;1500;1500;52;1500...</td>\n",
       "      <td>2;1;1;2;1;1;2;1;1;2;1;1;2;1;1;2;1;1;2;1;1;2;1;...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300</td>\n",
       "      <td>5000</td>\n",
       "      <td>300</td>\n",
       "      <td>500</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1642571671</td>\n",
       "      <td>172.20.0.3</td>\n",
       "      <td>42438</td>\n",
       "      <td>172.18.0.2</td>\n",
       "      <td>5001</td>\n",
       "      <td>6</td>\n",
       "      <td>180000</td>\n",
       "      <td>2444</td>\n",
       "      <td>120</td>\n",
       "      <td>47</td>\n",
       "      <td>1642571671205;1642571671205;1642571671205;1642...</td>\n",
       "      <td>52;1500;1500;52;1500;1500;52;1500;1500;52;1500...</td>\n",
       "      <td>2;1;1;2;1;1;2;1;1;2;1;1;2;1;1;2;1;1;2;1;1;2;1;...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300</td>\n",
       "      <td>5000</td>\n",
       "      <td>300</td>\n",
       "      <td>500</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1642571672</td>\n",
       "      <td>172.20.0.3</td>\n",
       "      <td>42438</td>\n",
       "      <td>172.18.0.2</td>\n",
       "      <td>5001</td>\n",
       "      <td>6</td>\n",
       "      <td>240000</td>\n",
       "      <td>3900</td>\n",
       "      <td>160</td>\n",
       "      <td>75</td>\n",
       "      <td>1642571672413;1642571672413;1642571672413;1642...</td>\n",
       "      <td>52;1500;1500;1500;1500;1500;1500;52;52;1500;15...</td>\n",
       "      <td>2;1;1;1;1;1;1;2;2;1;1;1;1;1;1;1;1;1;1;2;1;1;2;...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300</td>\n",
       "      <td>5000</td>\n",
       "      <td>300</td>\n",
       "      <td>500</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1642571673</td>\n",
       "      <td>172.20.0.3</td>\n",
       "      <td>42438</td>\n",
       "      <td>172.18.0.2</td>\n",
       "      <td>5001</td>\n",
       "      <td>6</td>\n",
       "      <td>1236000</td>\n",
       "      <td>24688</td>\n",
       "      <td>824</td>\n",
       "      <td>451</td>\n",
       "      <td>1642571673018;1642571673018;1642571673018;1642...</td>\n",
       "      <td>52;1500;1500;52;1500;1500;52;1500;1500;52;1500...</td>\n",
       "      <td>2;1;1;2;1;1;2;1;1;2;1;1;2;1;1;2;1;2;1;1;2;1;1;...</td>\n",
       "      <td>drop</td>\n",
       "      <td>1642571673.066695</td>\n",
       "      <td>300</td>\n",
       "      <td>5000</td>\n",
       "      <td>300</td>\n",
       "      <td>500</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>1642571978</td>\n",
       "      <td>172.20.0.3</td>\n",
       "      <td>42438</td>\n",
       "      <td>172.18.0.2</td>\n",
       "      <td>5001</td>\n",
       "      <td>6</td>\n",
       "      <td>303000</td>\n",
       "      <td>4212</td>\n",
       "      <td>202</td>\n",
       "      <td>81</td>\n",
       "      <td>1642571978004;1642571978004;1642571978004;1642...</td>\n",
       "      <td>52;1500;1500;52;1500;1500;52;1500;1500;1500;15...</td>\n",
       "      <td>2;1;1;2;1;1;2;1;1;1;1;2;1;1;2;1;1;2;1;1;1;1;2;...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300</td>\n",
       "      <td>5000</td>\n",
       "      <td>300</td>\n",
       "      <td>500</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>1642571979</td>\n",
       "      <td>172.20.0.3</td>\n",
       "      <td>42438</td>\n",
       "      <td>172.18.0.2</td>\n",
       "      <td>5001</td>\n",
       "      <td>6</td>\n",
       "      <td>372000</td>\n",
       "      <td>4420</td>\n",
       "      <td>248</td>\n",
       "      <td>85</td>\n",
       "      <td>1642571979011;1642571979011;1642571979011;1642...</td>\n",
       "      <td>52;1500;1500;52;1500;1500;52;1500;1500;52;1500...</td>\n",
       "      <td>2;1;1;2;1;1;2;1;1;2;1;1;1;1;2;1;1;2;1;1;1;1;2;...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300</td>\n",
       "      <td>5000</td>\n",
       "      <td>300</td>\n",
       "      <td>500</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>1642571980</td>\n",
       "      <td>172.20.0.3</td>\n",
       "      <td>42438</td>\n",
       "      <td>172.18.0.2</td>\n",
       "      <td>5001</td>\n",
       "      <td>6</td>\n",
       "      <td>427500</td>\n",
       "      <td>5720</td>\n",
       "      <td>285</td>\n",
       "      <td>110</td>\n",
       "      <td>1642571980000;1642571980000;1642571980000;1642...</td>\n",
       "      <td>52;1500;1500;1500;1500;52;1500;1500;52;1500;15...</td>\n",
       "      <td>2;1;1;1;1;2;1;1;2;1;1;1;1;2;1;1;2;1;1;1;1;2;1;...</td>\n",
       "      <td>drop</td>\n",
       "      <td>1642571980.718539</td>\n",
       "      <td>300</td>\n",
       "      <td>5000</td>\n",
       "      <td>300</td>\n",
       "      <td>500</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>1642571981</td>\n",
       "      <td>172.20.0.3</td>\n",
       "      <td>42438</td>\n",
       "      <td>172.18.0.2</td>\n",
       "      <td>5001</td>\n",
       "      <td>6</td>\n",
       "      <td>420000</td>\n",
       "      <td>6508</td>\n",
       "      <td>280</td>\n",
       "      <td>112</td>\n",
       "      <td>1642571981019;1642571981019;1642571981019;1642...</td>\n",
       "      <td>52;1500;1500;52;1500;52;1500;1500;1500;1500;52...</td>\n",
       "      <td>2;1;1;2;1;2;1;1;1;1;2;1;1;2;1;1;2;1;1;1;1;2;1;...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300</td>\n",
       "      <td>5000</td>\n",
       "      <td>300</td>\n",
       "      <td>500</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>1642571982</td>\n",
       "      <td>172.20.0.3</td>\n",
       "      <td>42438</td>\n",
       "      <td>172.18.0.2</td>\n",
       "      <td>5001</td>\n",
       "      <td>6</td>\n",
       "      <td>399000</td>\n",
       "      <td>5448</td>\n",
       "      <td>266</td>\n",
       "      <td>99</td>\n",
       "      <td>1642571982006;1642571982006;1642571982006;1642...</td>\n",
       "      <td>52;1500;1500;52;1500;1500;1500;1500;52;1500;15...</td>\n",
       "      <td>2;1;1;2;1;1;1;1;2;1;1;2;1;1;2;1;1;2;1;1;2;1;1;...</td>\n",
       "      <td>drop</td>\n",
       "      <td>1642571982.089803</td>\n",
       "      <td>300</td>\n",
       "      <td>5000</td>\n",
       "      <td>300</td>\n",
       "      <td>500</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>314 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Time         IP1  Port1         IP2  Port2  Proto  1->2Bytes  \\\n",
       "1    1642571669  172.20.0.3  42438  172.18.0.2   5001      6      13664   \n",
       "2    1642571670  172.20.0.3  42438  172.18.0.2   5001      6      30000   \n",
       "3    1642571671  172.20.0.3  42438  172.18.0.2   5001      6     180000   \n",
       "4    1642571672  172.20.0.3  42438  172.18.0.2   5001      6     240000   \n",
       "5    1642571673  172.20.0.3  42438  172.18.0.2   5001      6    1236000   \n",
       "..          ...         ...    ...         ...    ...    ...        ...   \n",
       "316  1642571978  172.20.0.3  42438  172.18.0.2   5001      6     303000   \n",
       "317  1642571979  172.20.0.3  42438  172.18.0.2   5001      6     372000   \n",
       "318  1642571980  172.20.0.3  42438  172.18.0.2   5001      6     427500   \n",
       "319  1642571981  172.20.0.3  42438  172.18.0.2   5001      6     420000   \n",
       "320  1642571982  172.20.0.3  42438  172.18.0.2   5001      6     399000   \n",
       "\n",
       "     2->1Bytes  1->2Pkts  2->1Pkts  \\\n",
       "1           60        11         1   \n",
       "2          520        20        10   \n",
       "3         2444       120        47   \n",
       "4         3900       160        75   \n",
       "5        24688       824       451   \n",
       "..         ...       ...       ...   \n",
       "316       4212       202        81   \n",
       "317       4420       248        85   \n",
       "318       5720       285       110   \n",
       "319       6508       280       112   \n",
       "320       5448       266        99   \n",
       "\n",
       "                                          packet_times  \\\n",
       "1    1642571669998;1642571669998;1642571669998;1642...   \n",
       "2    1642571670600;1642571670600;1642571670600;1642...   \n",
       "3    1642571671205;1642571671205;1642571671205;1642...   \n",
       "4    1642571672413;1642571672413;1642571672413;1642...   \n",
       "5    1642571673018;1642571673018;1642571673018;1642...   \n",
       "..                                                 ...   \n",
       "316  1642571978004;1642571978004;1642571978004;1642...   \n",
       "317  1642571979011;1642571979011;1642571979011;1642...   \n",
       "318  1642571980000;1642571980000;1642571980000;1642...   \n",
       "319  1642571981019;1642571981019;1642571981019;1642...   \n",
       "320  1642571982006;1642571982006;1642571982006;1642...   \n",
       "\n",
       "                                          packet_sizes  \\\n",
       "1    60;52;112;1500;1500;1500;1500;1500;1500;1500;1...   \n",
       "2    52;1500;1500;52;1500;1500;52;1500;1500;52;1500...   \n",
       "3    52;1500;1500;52;1500;1500;52;1500;1500;52;1500...   \n",
       "4    52;1500;1500;1500;1500;1500;1500;52;52;1500;15...   \n",
       "5    52;1500;1500;52;1500;1500;52;1500;1500;52;1500...   \n",
       "..                                                 ...   \n",
       "316  52;1500;1500;52;1500;1500;52;1500;1500;1500;15...   \n",
       "317  52;1500;1500;52;1500;1500;52;1500;1500;52;1500...   \n",
       "318  52;1500;1500;1500;1500;52;1500;1500;52;1500;15...   \n",
       "319  52;1500;1500;52;1500;52;1500;1500;1500;1500;52...   \n",
       "320  52;1500;1500;52;1500;1500;1500;1500;52;1500;15...   \n",
       "\n",
       "                                           packet_dirs event  \\\n",
       "1                             2;1;1;1;1;1;1;1;1;1;1;1;   NaN   \n",
       "2    2;1;1;2;1;1;2;1;1;2;1;1;2;1;1;2;1;1;2;1;1;2;1;...   NaN   \n",
       "3    2;1;1;2;1;1;2;1;1;2;1;1;2;1;1;2;1;1;2;1;1;2;1;...   NaN   \n",
       "4    2;1;1;1;1;1;1;2;2;1;1;1;1;1;1;1;1;1;1;2;1;1;2;...   NaN   \n",
       "5    2;1;1;2;1;1;2;1;1;2;1;1;2;1;1;2;1;2;1;1;2;1;1;...  drop   \n",
       "..                                                 ...   ...   \n",
       "316  2;1;1;2;1;1;2;1;1;1;1;2;1;1;2;1;1;2;1;1;1;1;2;...   NaN   \n",
       "317  2;1;1;2;1;1;2;1;1;2;1;1;1;1;2;1;1;2;1;1;1;1;2;...   NaN   \n",
       "318  2;1;1;1;1;2;1;1;2;1;1;1;1;2;1;1;2;1;1;1;1;2;1;...  drop   \n",
       "319  2;1;1;2;1;2;1;1;1;1;2;1;1;2;1;1;2;1;1;1;1;2;1;...   NaN   \n",
       "320  2;1;1;2;1;1;1;1;2;1;1;2;1;1;2;1;1;2;1;1;2;1;1;...  drop   \n",
       "\n",
       "             drop_unix  latency  loss  later_latency  later_loss  \\\n",
       "1                  NaN      300  5000            300         500   \n",
       "2                  NaN      300  5000            300         500   \n",
       "3                  NaN      300  5000            300         500   \n",
       "4                  NaN      300  5000            300         500   \n",
       "5    1642571673.066695      300  5000            300         500   \n",
       "..                 ...      ...   ...            ...         ...   \n",
       "316                NaN      300  5000            300         500   \n",
       "317                NaN      300  5000            300         500   \n",
       "318  1642571980.718539      300  5000            300         500   \n",
       "319                NaN      300  5000            300         500   \n",
       "320  1642571982.089803      300  5000            300         500   \n",
       "\n",
       "     deterministic  \n",
       "1             True  \n",
       "2             True  \n",
       "3             True  \n",
       "4             True  \n",
       "5             True  \n",
       "..             ...  \n",
       "316           True  \n",
       "317           True  \n",
       "318           True  \n",
       "319           True  \n",
       "320           True  \n",
       "\n",
       "[314 rows x 20 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = readfilerun_simple('data/raw/switch/20220119T055429_300-5000-true-300-500-iperf.csv', 'data/raw/switch')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c7ea5459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/raw/train', 'r/20220116T055105', '20-100-true-20-100-iperf.csv']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'data/raw/train_r/20220116T055105_20-100-true-20-100-iperf.csv'.split('_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c4166547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['20', '100', 'true', '20', '100']\n"
     ]
    }
   ],
   "source": [
    "df = readfilerun_simple('data/raw/train_r/20220116T055105_20-100-true-20-100-iperf.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "56b66dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def readfilerun(run_):#, output_dir):\n",
    "#     outdir = os.path.join(os.getcwd() , \"data3\", \"tempdata3\")\n",
    "#     names = listdir('data3') # all filenames in data\n",
    "#     daneruns = [x for x in names if not 'losslog' in x]\n",
    "#     daneruns.remove('tempdata3')\n",
    "    \n",
    "#     # daneruns = ['data/20220116T055105_20-100-true-20-100-iperf.csv', 'data/20220116T055942_20-250-true-20-250-iperf.csv']\n",
    "#     losslogs = [x for x in names if 'losslog' in x]\n",
    "#     #print(losslogs)\n",
    "#     for count, run in enumerate(daneruns):\n",
    "#         print(count)\n",
    "#         # print(run) #for debug\n",
    "#         curr_losslog = losslogs[count]\n",
    "#         print(\"run: \", run)\n",
    "#         run_labels = run.split('_')[1].split('.')[0].split('-')\n",
    "#         print(\"run_labels:\", run_labels)\n",
    "#         temp_label_str = '-'.join(run_labels) \n",
    "#         #print(temp_label_str)\n",
    "#         losslog = f'data3/{curr_losslog}' #losslog filename str\n",
    "#         #print(f'data3/{run}')\n",
    "#         #print(losslog)\n",
    "#         run_df = pd.read_csv(f'data3/{run}')\n",
    "#         losslog_df = pd.read_csv(losslog, header=None).rename(\n",
    "#             columns={0:'event', 1:'drop_unix', 2:'IP1', 3:'Port1', 4:'IP2', 5:'Port2', 6:'Proto'})\n",
    "#         losslog_df['Time'] = losslog_df['drop_unix'].astype(int)\n",
    "#         losslog_df = losslog_df.groupby(['Time', 'IP1', 'Port1', 'IP2', 'Port2', 'Proto']).agg(lambda x: ';'.join(x.astype(str))).reset_index()\n",
    "#         df = pd.merge(run_df, losslog_df, on=['Time', 'IP1', 'Port1', 'IP2', 'Port2', 'Proto'], how=\"left\") # merge on fivetuple key\n",
    "#         # df.fillna(inplace=True, value=-1) #TODO plan implementation of dealing with null values\n",
    "#         # df['event'] =  # TODO change to 3 different profiles: no drop, drop, and switch event\n",
    "#         df = df[df['Proto'] == df['Proto'].mode()[0]] # selects relevant non ipv6 int(connection\n",
    "        \n",
    "#         ## adding labels\n",
    "#         df['latency'] = int(run_labels[0])\n",
    "#         df['loss'] = int(run_labels[1])\n",
    "#         df['later_latency'] = int(run_labels[3])\n",
    "#         df['later_loss'] = int(run_labels[4])\n",
    "#         df['deterministic'] = bool(run_labels[2])\n",
    "        \n",
    "#         #TODO future implementation of boolean flag for when the switch happens so we know when to use later lat/loss\n",
    "        \n",
    "#         df.to_csv(f'{outdir}/labeled-from-{run_}_{temp_label_str}.csv') # save to temporary output directory: just merging takes a bit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a743089b",
   "metadata": {},
   "source": [
    "NOTE TO SELF: this is wip on gen, you just copied lauras gen and are modifying it for your own use. Target for work tomorrow is getting it all to run using the main function, the model building should be trivial but gen is kicking your ass since its all the etl garbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7340251f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "cfcc6367",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "61f89425",
   "metadata": {},
   "source": [
    "#### eda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1af48433",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_eda(cond, lst, filen1, filen2, filen3):\n",
    "    unseen = ''\n",
    "    if cond =='unseen': \n",
    "        unseen = 'unseen'\n",
    "    \n",
    "    fpath1 = os.path.join(os.getcwd() , \"outputs\", unseen + filen1)\n",
    "    df_1 = pd.read_csv(fpath1)\n",
    "    fpath2 = os.path.join(os.getcwd() , \"outputs\", unseen + filen2)\n",
    "    df_2 = pd.read_csv(fpath2)\n",
    "    fpath3 = os.path.join(os.getcwd() , \"outputs\", unseen + filen3)\n",
    "    df_3 = pd.read_csv(fpath3)\n",
    "    \n",
    "    plottogether(cond, lst, df_1, filen1.strip(\".csv\")) # trends over subset\n",
    "    plottogether(cond, lst, df_3, filen3.strip(\".csv\")) # trends over entire data\n",
    "    plotloss(cond, df_2)\n",
    "\n",
    "    plot_correlation_matrix(cond, df_2) # correlation matrix\n",
    "    plotlongest(df_3, cond)\n",
    "    # below makes rest of visualizations\n",
    "    plotbytes(df_3)\n",
    "    #plot_detailed_bytes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdddc05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "28eb31ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overlaying model predictions and plotting detailed bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b510eac4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30152c8c",
   "metadata": {},
   "source": [
    "#### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2cb10284",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_feat(cond, df, cols, p, df_u): \n",
    "    unseen = ''\n",
    "    if cond =='unseen': \n",
    "        unseen = 'unseen'\n",
    "    # col is feauture comb\n",
    "    # p is for loss or latency   1: loss  # 2 : latency\n",
    "    X = df[cols]\n",
    "    \n",
    "    X2 = df_u[cols]\n",
    "\n",
    "    if p == 1:  # flag found in test_mse\n",
    "        y = df.loss\n",
    "        y2 = df_u.loss\n",
    "    if p == 2: \n",
    "        y = df.latency\n",
    "        y2 = df_u.latency\n",
    "        \n",
    "    # randomly split into train and test sets, test set is 80% of data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "    if unseen == 'unseen': \n",
    "        X_test = X2\n",
    "        y_test = y2\n",
    "    \n",
    "    clf = DecisionTreeRegressor()\n",
    "    clf = clf.fit(X_train,y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    acc1 = mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "    clf2 = RandomForestRegressor(n_estimators=10)\n",
    "    clf2 = clf2.fit(X_train,y_train)\n",
    "    y_pred2 = clf2.predict(X_test)\n",
    "    acc2= mean_squared_error(y_test, y_pred2)\n",
    "    \n",
    "    clf3 = ExtraTreesRegressor(n_estimators=10)\n",
    "    clf3 = clf3.fit(X_train,y_train)\n",
    "    y_pred3 = clf3.predict(X_test)\n",
    "    acc3= mean_squared_error(y_test, y_pred3)\n",
    "    \n",
    "    pca = PCA() \n",
    "    X_transformed = pca.fit_transform(X_train) \n",
    "    cl = DecisionTreeRegressor() \n",
    "    cl.fit(X_transformed, y_train)\n",
    "    newdata_transformed = pca.transform(X_test)\n",
    "    y_pred4 = cl.predict(newdata_transformed)\n",
    "    acc4 = mean_squared_error(y_test, y_pred4)\n",
    "    \n",
    "    clf_gbc = GradientBoostingRegressor(random_state=0)\n",
    "    clf_gbc.fit(X_train, y_train)\n",
    "    y_pred5 = clf_gbc.predict(X_test)\n",
    "    acc5 = mean_squared_error(y_test, y_pred5) \n",
    "    return [acc1, acc2, acc3, acc4, acc5]\n",
    "\n",
    "\n",
    "def test_mse(cond, all_comb1, all_comb2):\n",
    "    unseen = ''\n",
    "    if cond =='unseen': \n",
    "        unseen = 'unseen'\n",
    "    filedir_unseen = os.path.join(os.getcwd(), \"outputs\", unseen + \"combined_t.csv\")\n",
    "    df_unseen = pd.read_csv(filedir_unseen)\n",
    "    filedir = os.path.join(os.getcwd(), \"outputs\", \"combined_t.csv\")\n",
    "    df = pd.read_csv(filedir)\n",
    "    \n",
    "    all_comb1 = pd.Series(all_comb1).apply(lambda x: list(x))\n",
    "    all_comb2 = pd.Series(all_comb2).apply(lambda x: list(x))\n",
    "    \n",
    "    dt = []\n",
    "    rf = []\n",
    "    et = []\n",
    "    pca = []\n",
    "    gbc = []\n",
    "    for i in all_comb1:\n",
    "        acc_loss = test_feat(cond, df, i, 1, df_unseen)\n",
    "        dt.append(acc_loss[0])  \n",
    "        rf.append(acc_loss[1])  \n",
    "        et.append(acc_loss[2])   \n",
    "        pca.append(acc_loss[3])   \n",
    "        gbc.append(acc_loss[4])\n",
    "        \n",
    "    # optimze by adding a flag called losslat to avoid making two dataframes of results\n",
    "    dt2 = []\n",
    "    rf2 = []\n",
    "    et2 = []\n",
    "    pca2 = []\n",
    "    gbc2 = []\n",
    "    for i in all_comb2:\n",
    "        # 1 = loss\n",
    "        # 2 = latency\n",
    "        acc_latency = test_feat(cond, df, i, 2, df_unseen)\n",
    "        dt2.append(acc_latency[0])\n",
    "        rf2.append(acc_latency[1])\n",
    "        et2.append(acc_latency[2]) \n",
    "        pca2.append(acc_latency[3])\n",
    "        gbc2.append(acc_latency[4])\n",
    "        \n",
    "    dict1 = pd.DataFrame({'feat': all_comb1, 'dt': dt, 'rf': rf, 'et': et, 'pca': pca, 'gbc': gbc})\n",
    "    dict2 = pd.DataFrame({'feat2': all_comb2, 'dt2': dt2, 'rf2': rf2, 'et2': et2, 'pca2': pca2, 'gbc2': gbc2})\n",
    "    \n",
    "    path = os.path.join(os.getcwd() , \"outputs\")\n",
    "    dict1.to_csv(os.path.join(path, unseen + \"feat_df1.csv\"), index = False)\n",
    "    dict2.to_csv(os.path.join(path, unseen + \"feat_df2.csv\"), index = False)\n",
    "\n",
    "\n",
    "def best_performance(cond):\n",
    "    unseen = ''\n",
    "    if cond == 'unseen': \n",
    "        unseen = 'unseen'\n",
    "    #print(\"finding best loss performance\")\n",
    "    filedir1 = os.path.join(os.getcwd(), \"outputs\", unseen + \"feat_df1.csv\")\n",
    "    df1 = pd.read_csv(filedir1)\n",
    "    print( \"\\n\")\n",
    "    print(\"Loss Performance sorted from lowest to highest\", \"\\n\")\n",
    "    print(df1.sort_values(by=['dt', 'rf', 'et', 'pca'], ascending = True)[:5], \"\\n\")\n",
    "    \n",
    "    #print(\"finding best latency performance\")\n",
    "    filedir2 = os.path.join(os.getcwd(), \"outputs\", unseen + \"feat_df2.csv\")\n",
    "    df2 = pd.read_csv(filedir2)\n",
    "    print( \"\\n\")\n",
    "    print(\"Latency Performance sorted from lowest to highest\", \"\\n\")\n",
    "    print(df2.sort_values(by=['dt2', 'rf2', 'et2', 'pca2'], ascending = True)[:5], \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48801d7b",
   "metadata": {},
   "source": [
    "#### main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "cc580300",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(targets):\n",
    "\n",
    "    transform_config = json.load(open('config/transform.json'))\n",
    "    columns = json.load(open('config/columns.json'))\n",
    "    eda_config = json.load(open('config/eda.json'))\n",
    "    all_config = json.load(open(\"config/all.json\"))\n",
    "\n",
    "    test_unseen = 'unseen'\n",
    "    test_seen = 'seen'\n",
    "    \n",
    "    cond1 = True\n",
    "    cond2 = False\n",
    "\n",
    "    if 'data' in targets:\n",
    "        \"\"\"generating feat from unseen and seen data\"\"\"\n",
    "        # readfilerun('data/raw/train_r', 'data/temp/tempdata') # TODO uncomment\n",
    "        gen(test_seen, **transform_config)\n",
    "#         gen(test_unseen, **transform_config)\n",
    "\n",
    "    if 'eda' in targets:  \n",
    "        # readfilerun('data/raw/train_r', 'data/tempdata') \n",
    "#         gen(test_seen, **transform_config)\n",
    "        main_eda(test_seen, **eda_config)\n",
    "        print(\"EDA saved to outputs/eda/ folder\")\n",
    "\n",
    "    if 'train' in targets:\n",
    "        \"trains tests in this target\"\n",
    "#         readfilerun('data3', 'tempdata3') \n",
    "#         gen(test_seen, **transform_config)\n",
    "                \n",
    "        comb1 = getAllCombinations(1)\n",
    "        comb2 = getAllCombinations(2)\n",
    "        \n",
    "        print(\"Testing on seen data: \")\n",
    "        test_mse(test_seen, comb1, comb2)\n",
    "        best_performance(test_seen)\n",
    "                        \n",
    "    if \"inference\" in targets: \n",
    "        print('tba')\n",
    "#         readfilerun('data3', 'tempdata3') \n",
    "#         gen(test_seen, **transform_config)\n",
    "#         gen(test_unseen, **transform_config)\n",
    "        \n",
    "#         comb1 = getAllCombinations(1)\n",
    "#         comb2 = getAllCombinations(2)\n",
    "        \n",
    "#         print(\"Testing on unseen data: \")\n",
    "#         test_mse(test_unseen, comb1, comb2)\n",
    "#         best_performance(test_unseen)\n",
    "            \n",
    "    if \"test\" in targets: \n",
    "        \"\"\" runs all targets on sample data\"\"\"\n",
    "        print('tba')\n",
    "#         readfilerun('data3', 'tempdata3') \n",
    "#         gen(test_seen, **transform_config)\n",
    "#         gen(test_unseen, **transform_config)\n",
    "        \n",
    "#         main_eda(test_seen, **eda_config)\n",
    "#         print(\"EDA saved to outputs/eda/ folder\")\n",
    "        \n",
    "#         comb1 = getAllCombinations(1)\n",
    "#         comb2 = getAllCombinations(2)\n",
    "        \n",
    "#         print(\"Testing on seen data: \")\n",
    "#         test_mse(test_seen, comb1, comb2)\n",
    "#         best_performance(test_seen)\n",
    "        \n",
    "#         print(\"Testing on unseen data: \")\n",
    "#         test_mse(test_unseen, comb1, comb2)\n",
    "#         best_performance(test_unseen)\n",
    "        \n",
    "    if 'all' in targets: \n",
    "        print('tba')\n",
    "        \n",
    "# if __name__ == '__main__':\n",
    "\n",
    "#     targets = sys.argv[1:]\n",
    "#     main(targets)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "078c564e",
   "metadata": {},
   "source": [
    "path_ = os.path.join(os.getcwd() , \"outputs\")\n",
    "fp = os.path.join(path_, \"combined_all.csv\")\n",
    "fp2 = os.path.join(path_, \"combined_subset.csv\")\n",
    "dfall = pd.read_csv(fp)\n",
    "df_subset = pd.read_csv(fp2)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "00f3c7c7",
   "metadata": {},
   "source": [
    "readfilerun('data3')#, 'tempdata3') # takes a long time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f3a82d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = ['data', 'eda', 'train', 'inference', 'test', 'all']\n",
    "# main(targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "9aa4587d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transforming seen data\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_100-100-true-100-100.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_100-1000-true-100-1000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_100-10000-true-100-10000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_100-11000-true-100-11000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_100-12000-true-100-12000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_100-13000-true-100-13000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_100-14000-true-100-14000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_100-15000-true-100-15000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_100-16000-true-100-16000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_100-17000-true-100-17000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_100-18000-true-100-18000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_100-19000-true-100-19000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_100-2000-true-100-2000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_100-20000-true-100-20000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_100-250-true-100-250.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_100-3000-true-100-3000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_100-4000-true-100-4000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_100-500-true-100-500.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_100-5000-true-100-5000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_100-6000-true-100-6000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_100-7000-true-100-7000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_100-8000-true-100-8000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_100-9000-true-100-9000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_150-100-true-150-100.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_150-1000-true-150-1000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_150-10000-true-150-10000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_150-11000-true-150-11000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_150-12000-true-150-12000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_150-13000-true-150-13000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_150-14000-true-150-14000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_150-15000-true-150-15000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_150-16000-true-150-16000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_150-17000-true-150-17000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_150-18000-true-150-18000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_150-19000-true-150-19000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_150-2000-true-150-2000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_150-20000-true-150-20000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_150-250-true-150-250.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_150-3000-true-150-3000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_150-4000-true-150-4000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_150-500-true-150-500.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_150-5000-true-150-5000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_150-6000-true-150-6000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_150-7000-true-150-7000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_150-8000-true-150-8000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_150-9000-true-150-9000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_20-100-true-20-100.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_20-1000-true-20-1000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_20-10000-true-20-10000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_20-11000-true-20-11000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_20-12000-true-20-12000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_20-13000-true-20-13000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_20-14000-true-20-14000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_20-15000-true-20-15000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_20-16000-true-20-16000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_20-17000-true-20-17000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_20-18000-true-20-18000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_20-19000-true-20-19000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_20-2000-true-20-2000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_20-20000-true-20-20000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_20-21000-true-20-21000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_20-22000-true-20-22000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_20-23000-true-20-23000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_20-250-true-20-250.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_20-3000-true-20-3000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_20-4000-true-20-4000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_20-500-true-20-500.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_20-5000-true-20-5000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_20-6000-true-20-6000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_20-7000-true-20-7000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_20-8000-true-20-8000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_20-9000-true-20-9000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_200-100-true-200-100.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_200-1000-true-200-1000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_200-10000-true-200-10000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_200-11000-true-200-11000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_200-12000-true-200-12000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_200-13000-true-200-13000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_200-14000-true-200-14000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_200-15000-true-200-15000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_200-16000-true-200-16000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_200-17000-true-200-17000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_200-18000-true-200-18000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_200-19000-true-200-19000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_200-2000-true-200-2000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_200-20000-true-200-20000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_200-250-true-200-250.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_200-3000-true-200-3000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_200-4000-true-200-4000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_200-500-true-200-500.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_200-5000-true-200-5000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_200-6000-true-200-6000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_200-7000-true-200-7000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_200-8000-true-200-8000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_200-9000-true-200-9000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_250-100-true-250-100.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_250-1000-true-250-1000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_250-10000-true-250-10000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_250-11000-true-250-11000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_250-12000-true-250-12000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_250-13000-true-250-13000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_250-14000-true-250-14000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_250-15000-true-250-15000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_250-16000-true-250-16000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_250-17000-true-250-17000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_250-18000-true-250-18000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_250-19000-true-250-19000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_250-2000-true-250-2000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_250-20000-true-250-20000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_250-250-true-250-250.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_250-3000-true-250-3000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_250-4000-true-250-4000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_250-500-true-250-500.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_250-5000-true-250-5000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_250-6000-true-250-6000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_250-7000-true-250-7000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_250-8000-true-250-8000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_250-9000-true-250-9000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_300-100-true-300-100.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_300-1000-true-300-1000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_300-10000-true-300-10000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_300-11000-true-300-11000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_300-12000-true-300-12000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_300-13000-true-300-13000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_300-14000-true-300-14000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_300-15000-true-300-15000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_300-16000-true-300-16000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_300-17000-true-300-17000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_300-18000-true-300-18000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_300-19000-true-300-19000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_300-2000-true-300-2000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_300-20000-true-300-20000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_300-250-true-300-250.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_300-3000-true-300-3000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_300-4000-true-300-4000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_300-500-true-300-500.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_300-5000-true-300-5000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_300-6000-true-300-6000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_300-7000-true-300-7000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_300-8000-true-300-8000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_300-9000-true-300-9000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_350-100-true-350-100.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_350-1000-true-350-1000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_350-10000-true-350-10000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_350-11000-true-350-11000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_350-12000-true-350-12000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_350-13000-true-350-13000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_350-14000-true-350-14000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_350-15000-true-350-15000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_350-16000-true-350-16000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_350-17000-true-350-17000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_350-18000-true-350-18000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_350-19000-true-350-19000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_350-2000-true-350-2000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_350-20000-true-350-20000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_350-250-true-350-250.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_350-3000-true-350-3000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_350-3000-true-350-500.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_350-4000-true-350-4000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_350-500-true-350-500.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_350-5000-true-350-5000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_350-6000-true-350-6000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_350-7000-true-350-7000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_350-8000-true-350-8000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_350-9000-true-350-9000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_400-100-true-400-100.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_400-1000-true-400-1000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_400-12000-true-400-12000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_400-13000-true-400-13000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_400-14000-true-400-14000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_400-15000-true-400-15000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_400-16000-true-400-16000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_400-17000-true-400-17000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_400-18000-true-400-18000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_400-19000-true-400-19000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_400-2000-true-400-2000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_400-20000-true-400-20000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_400-250-true-400-250.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_400-3000-true-400-3000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_400-4000-true-400-4000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_400-500-true-400-500.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_400-5000-true-400-5000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_400-6000-true-400-6000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_400-7000-true-400-7000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_400-8000-true-400-8000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_450-100-true-450-100.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_450-1000-true-450-1000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_450-10000-true-450-10000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_450-11000-true-450-11000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_450-12000-true-450-12000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_450-13000-true-450-13000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_450-14000-true-450-14000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_450-15000-true-450-15000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_450-16000-true-450-16000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_450-17000-true-450-17000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_450-18000-true-450-18000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_450-19000-true-450-19000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_450-2000-true-450-2000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_450-20000-true-450-20000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_450-250-true-450-250.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_450-3000-true-450-3000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_450-4000-true-450-4000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_450-500-true-450-500.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_450-5000-true-450-5000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_450-6000-true-450-6000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_450-7000-true-450-7000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_450-8000-true-450-8000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_450-9000-true-450-9000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_50-100-true-50-100.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_50-1000-true-50-1000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_50-10000-true-50-10000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_50-11000-true-50-11000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_50-12000-true-50-12000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_50-13000-true-50-13000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_50-14000-true-50-14000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_50-15000-true-50-15000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_50-16000-true-50-16000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_50-17000-true-50-17000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_50-18000-true-50-18000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_50-19000-true-50-19000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_50-2000-true-50-2000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_50-20000-true-50-20000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_50-21000-true-50-21000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_50-250-true-50-250.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_50-3000-true-50-3000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_50-4000-true-50-4000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_50-500-true-50-500.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_50-5000-true-50-5000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_50-6000-true-50-6000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_50-7000-true-50-7000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_50-8000-true-50-8000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_50-9000-true-50-9000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_500-100-true-500-100.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_500-1000-true-500-1000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_500-10000-true-500-10000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_500-11000-true-500-11000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_500-12000-true-500-12000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_500-13000-true-500-13000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_500-14000-true-500-14000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_500-15000-true-500-15000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_500-16000-true-500-16000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_500-17000-true-500-17000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_500-18000-true-500-18000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_500-19000-true-500-19000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_500-2000-true-500-2000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_500-20000-true-500-20000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_500-21000-true-500-21000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_500-250-true-500-250.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_500-3000-true-500-3000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_500-4000-true-500-4000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_500-500-true-500-500.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_500-5000-true-500-5000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_500-6000-true-500-6000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_500-7000-true-500-7000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_500-8000-true-500-8000.csv\n",
      "c:\\Users\\Staro\\Documents\\GitHub\\Q2\\data\\temp/tempdata\\labeled_500-9000-true-500-9000.csv\n",
      "combined_finished\n",
      "combined_all_finished\n",
      "transformed_finished\n"
     ]
    }
   ],
   "source": [
    "main(targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab445c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "79d30554",
   "metadata": {},
   "source": [
    "MAKING pipeline: , tst on data with change in loss later\n",
    "    \n",
    "    comb[some index]\n",
    "    \n",
    "    dt() - untrained\n",
    "    \n",
    "    dt( comb) - train, or grid search on it\n",
    "    \n",
    "    et() - \n",
    "    \n",
    "    plot them on top of eachother\n",
    "    \n",
    "    test(single dataset - aggregated over subset )# overserved or not\n",
    "    \n",
    "    plot the bytes, loss records (loss log), and expanded model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "3f16b215",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "path = os.path.join(os.getcwd() , \"outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "28f9419d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all combinations generated\n",
      "all combinations generated\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'total_pkts_max'},\n",
       " {'total_pkt_sizes', 'total_pkts_max'},\n",
       " {'total_pkt_sizes'},\n",
       " {'2->1Bytes', 'total_pkts_max'},\n",
       " {'2->1Bytes', 'total_pkt_sizes', 'total_pkts_max'},\n",
       " {'2->1Bytes', 'total_pkt_sizes'},\n",
       " {'2->1Bytes'},\n",
       " {'number_ms', 'total_pkts_max'},\n",
       " {'number_ms', 'total_pkt_sizes', 'total_pkts_max'},\n",
       " {'number_ms', 'total_pkt_sizes'},\n",
       " {'2->1Bytes', 'number_ms', 'total_pkts_max'},\n",
       " {'2->1Bytes', 'number_ms', 'total_pkt_sizes', 'total_pkts_max'},\n",
       " {'2->1Bytes', 'number_ms', 'total_pkt_sizes'},\n",
       " {'2->1Bytes', 'number_ms'},\n",
       " {'number_ms'},\n",
       " {'mean_tdelta', 'total_pkts_max'},\n",
       " {'mean_tdelta', 'total_pkt_sizes', 'total_pkts_max'},\n",
       " {'mean_tdelta', 'total_pkt_sizes'},\n",
       " {'2->1Bytes', 'mean_tdelta', 'total_pkts_max'},\n",
       " {'2->1Bytes', 'mean_tdelta', 'total_pkt_sizes', 'total_pkts_max'},\n",
       " {'2->1Bytes', 'mean_tdelta', 'total_pkt_sizes'},\n",
       " {'2->1Bytes', 'mean_tdelta'},\n",
       " {'mean_tdelta', 'number_ms', 'total_pkts_max'},\n",
       " {'mean_tdelta', 'number_ms', 'total_pkt_sizes', 'total_pkts_max'},\n",
       " {'mean_tdelta', 'number_ms', 'total_pkt_sizes'},\n",
       " {'2->1Bytes', 'mean_tdelta', 'number_ms', 'total_pkts_max'},\n",
       " {'2->1Bytes',\n",
       "  'mean_tdelta',\n",
       "  'number_ms',\n",
       "  'total_pkt_sizes',\n",
       "  'total_pkts_max'},\n",
       " {'2->1Bytes', 'mean_tdelta', 'number_ms', 'total_pkt_sizes'},\n",
       " {'2->1Bytes', 'mean_tdelta', 'number_ms'},\n",
       " {'mean_tdelta', 'number_ms'},\n",
       " {'mean_tdelta'},\n",
       " {'total_pkts', 'total_pkts_max'},\n",
       " {'total_pkt_sizes', 'total_pkts', 'total_pkts_max'},\n",
       " {'total_pkt_sizes', 'total_pkts'},\n",
       " {'2->1Bytes', 'total_pkts', 'total_pkts_max'},\n",
       " {'2->1Bytes', 'total_pkt_sizes', 'total_pkts', 'total_pkts_max'},\n",
       " {'2->1Bytes', 'total_pkt_sizes', 'total_pkts'},\n",
       " {'2->1Bytes', 'total_pkts'},\n",
       " {'number_ms', 'total_pkts', 'total_pkts_max'},\n",
       " {'number_ms', 'total_pkt_sizes', 'total_pkts', 'total_pkts_max'},\n",
       " {'number_ms', 'total_pkt_sizes', 'total_pkts'},\n",
       " {'2->1Bytes', 'number_ms', 'total_pkts', 'total_pkts_max'},\n",
       " {'2->1Bytes', 'number_ms', 'total_pkt_sizes', 'total_pkts', 'total_pkts_max'},\n",
       " {'2->1Bytes', 'number_ms', 'total_pkt_sizes', 'total_pkts'},\n",
       " {'2->1Bytes', 'number_ms', 'total_pkts'},\n",
       " {'number_ms', 'total_pkts'},\n",
       " {'mean_tdelta', 'total_pkts', 'total_pkts_max'},\n",
       " {'mean_tdelta', 'total_pkt_sizes', 'total_pkts', 'total_pkts_max'},\n",
       " {'mean_tdelta', 'total_pkt_sizes', 'total_pkts'},\n",
       " {'2->1Bytes', 'mean_tdelta', 'total_pkts', 'total_pkts_max'},\n",
       " {'2->1Bytes',\n",
       "  'mean_tdelta',\n",
       "  'total_pkt_sizes',\n",
       "  'total_pkts',\n",
       "  'total_pkts_max'},\n",
       " {'2->1Bytes', 'mean_tdelta', 'total_pkt_sizes', 'total_pkts'},\n",
       " {'2->1Bytes', 'mean_tdelta', 'total_pkts'},\n",
       " {'mean_tdelta', 'number_ms', 'total_pkts', 'total_pkts_max'},\n",
       " {'mean_tdelta',\n",
       "  'number_ms',\n",
       "  'total_pkt_sizes',\n",
       "  'total_pkts',\n",
       "  'total_pkts_max'},\n",
       " {'mean_tdelta', 'number_ms', 'total_pkt_sizes', 'total_pkts'},\n",
       " {'2->1Bytes', 'mean_tdelta', 'number_ms', 'total_pkts', 'total_pkts_max'},\n",
       " {'2->1Bytes',\n",
       "  'mean_tdelta',\n",
       "  'number_ms',\n",
       "  'total_pkt_sizes',\n",
       "  'total_pkts',\n",
       "  'total_pkts_max'},\n",
       " {'2->1Bytes', 'mean_tdelta', 'number_ms', 'total_pkt_sizes', 'total_pkts'},\n",
       " {'2->1Bytes', 'mean_tdelta', 'number_ms', 'total_pkts'},\n",
       " {'mean_tdelta', 'number_ms', 'total_pkts'},\n",
       " {'mean_tdelta', 'total_pkts'},\n",
       " {'total_pkts'},\n",
       " {'pkt sum', 'total_pkts_max'},\n",
       " {'pkt sum', 'total_pkt_sizes', 'total_pkts_max'},\n",
       " {'pkt sum', 'total_pkt_sizes'},\n",
       " {'2->1Bytes', 'pkt sum', 'total_pkts_max'},\n",
       " {'2->1Bytes', 'pkt sum', 'total_pkt_sizes', 'total_pkts_max'},\n",
       " {'2->1Bytes', 'pkt sum', 'total_pkt_sizes'},\n",
       " {'2->1Bytes', 'pkt sum'},\n",
       " {'number_ms', 'pkt sum', 'total_pkts_max'},\n",
       " {'number_ms', 'pkt sum', 'total_pkt_sizes', 'total_pkts_max'},\n",
       " {'number_ms', 'pkt sum', 'total_pkt_sizes'},\n",
       " {'2->1Bytes', 'number_ms', 'pkt sum', 'total_pkts_max'},\n",
       " {'2->1Bytes', 'number_ms', 'pkt sum', 'total_pkt_sizes', 'total_pkts_max'},\n",
       " {'2->1Bytes', 'number_ms', 'pkt sum', 'total_pkt_sizes'},\n",
       " {'2->1Bytes', 'number_ms', 'pkt sum'},\n",
       " {'number_ms', 'pkt sum'},\n",
       " {'mean_tdelta', 'pkt sum', 'total_pkts_max'},\n",
       " {'mean_tdelta', 'pkt sum', 'total_pkt_sizes', 'total_pkts_max'},\n",
       " {'mean_tdelta', 'pkt sum', 'total_pkt_sizes'},\n",
       " {'2->1Bytes', 'mean_tdelta', 'pkt sum', 'total_pkts_max'},\n",
       " {'2->1Bytes', 'mean_tdelta', 'pkt sum', 'total_pkt_sizes', 'total_pkts_max'},\n",
       " {'2->1Bytes', 'mean_tdelta', 'pkt sum', 'total_pkt_sizes'},\n",
       " {'2->1Bytes', 'mean_tdelta', 'pkt sum'},\n",
       " {'mean_tdelta', 'number_ms', 'pkt sum', 'total_pkts_max'},\n",
       " {'mean_tdelta', 'number_ms', 'pkt sum', 'total_pkt_sizes', 'total_pkts_max'},\n",
       " {'mean_tdelta', 'number_ms', 'pkt sum', 'total_pkt_sizes'},\n",
       " {'2->1Bytes', 'mean_tdelta', 'number_ms', 'pkt sum', 'total_pkts_max'},\n",
       " {'2->1Bytes',\n",
       "  'mean_tdelta',\n",
       "  'number_ms',\n",
       "  'pkt sum',\n",
       "  'total_pkt_sizes',\n",
       "  'total_pkts_max'},\n",
       " {'2->1Bytes', 'mean_tdelta', 'number_ms', 'pkt sum', 'total_pkt_sizes'},\n",
       " {'2->1Bytes', 'mean_tdelta', 'number_ms', 'pkt sum'},\n",
       " {'mean_tdelta', 'number_ms', 'pkt sum'},\n",
       " {'mean_tdelta', 'pkt sum'},\n",
       " {'pkt sum', 'total_pkts', 'total_pkts_max'},\n",
       " {'pkt sum', 'total_pkt_sizes', 'total_pkts', 'total_pkts_max'},\n",
       " {'pkt sum', 'total_pkt_sizes', 'total_pkts'},\n",
       " {'2->1Bytes', 'pkt sum', 'total_pkts', 'total_pkts_max'},\n",
       " {'2->1Bytes', 'pkt sum', 'total_pkt_sizes', 'total_pkts', 'total_pkts_max'},\n",
       " {'2->1Bytes', 'pkt sum', 'total_pkt_sizes', 'total_pkts'},\n",
       " {'2->1Bytes', 'pkt sum', 'total_pkts'},\n",
       " {'number_ms', 'pkt sum', 'total_pkts', 'total_pkts_max'},\n",
       " {'number_ms', 'pkt sum', 'total_pkt_sizes', 'total_pkts', 'total_pkts_max'},\n",
       " {'number_ms', 'pkt sum', 'total_pkt_sizes', 'total_pkts'},\n",
       " {'2->1Bytes', 'number_ms', 'pkt sum', 'total_pkts', 'total_pkts_max'},\n",
       " {'2->1Bytes',\n",
       "  'number_ms',\n",
       "  'pkt sum',\n",
       "  'total_pkt_sizes',\n",
       "  'total_pkts',\n",
       "  'total_pkts_max'},\n",
       " {'2->1Bytes', 'number_ms', 'pkt sum', 'total_pkt_sizes', 'total_pkts'},\n",
       " {'2->1Bytes', 'number_ms', 'pkt sum', 'total_pkts'},\n",
       " {'number_ms', 'pkt sum', 'total_pkts'},\n",
       " {'mean_tdelta', 'pkt sum', 'total_pkts', 'total_pkts_max'},\n",
       " {'mean_tdelta', 'pkt sum', 'total_pkt_sizes', 'total_pkts', 'total_pkts_max'},\n",
       " {'mean_tdelta', 'pkt sum', 'total_pkt_sizes', 'total_pkts'},\n",
       " {'2->1Bytes', 'mean_tdelta', 'pkt sum', 'total_pkts', 'total_pkts_max'},\n",
       " {'2->1Bytes',\n",
       "  'mean_tdelta',\n",
       "  'pkt sum',\n",
       "  'total_pkt_sizes',\n",
       "  'total_pkts',\n",
       "  'total_pkts_max'},\n",
       " {'2->1Bytes', 'mean_tdelta', 'pkt sum', 'total_pkt_sizes', 'total_pkts'},\n",
       " {'2->1Bytes', 'mean_tdelta', 'pkt sum', 'total_pkts'},\n",
       " {'mean_tdelta', 'number_ms', 'pkt sum', 'total_pkts', 'total_pkts_max'},\n",
       " {'mean_tdelta',\n",
       "  'number_ms',\n",
       "  'pkt sum',\n",
       "  'total_pkt_sizes',\n",
       "  'total_pkts',\n",
       "  'total_pkts_max'},\n",
       " {'mean_tdelta', 'number_ms', 'pkt sum', 'total_pkt_sizes', 'total_pkts'},\n",
       " {'2->1Bytes',\n",
       "  'mean_tdelta',\n",
       "  'number_ms',\n",
       "  'pkt sum',\n",
       "  'total_pkts',\n",
       "  'total_pkts_max'},\n",
       " {'2->1Bytes',\n",
       "  'mean_tdelta',\n",
       "  'number_ms',\n",
       "  'pkt sum',\n",
       "  'total_pkt_sizes',\n",
       "  'total_pkts',\n",
       "  'total_pkts_max'},\n",
       " {'2->1Bytes',\n",
       "  'mean_tdelta',\n",
       "  'number_ms',\n",
       "  'pkt sum',\n",
       "  'total_pkt_sizes',\n",
       "  'total_pkts'},\n",
       " {'2->1Bytes', 'mean_tdelta', 'number_ms', 'pkt sum', 'total_pkts'},\n",
       " {'mean_tdelta', 'number_ms', 'pkt sum', 'total_pkts'},\n",
       " {'mean_tdelta', 'pkt sum', 'total_pkts'},\n",
       " {'pkt sum', 'total_pkts'},\n",
       " {'pkt sum'}]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comb1 = getAllCombinations(1)\n",
    "comb2 = getAllCombinations(2)\n",
    "comb1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1cca963b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fname' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-112-bb176801c6d7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#fname = 'labeled-from-data2_100-10000-true-100-10000.csv'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mgenviz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'seen'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'fname' is not defined"
     ]
    }
   ],
   "source": [
    "#fname = 'labeled-from-data2_100-10000-true-100-10000.csv'\n",
    "genviz('seen', fname, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca742245",
   "metadata": {},
   "outputs": [],
   "source": [
    "newfname = 'combined_t.csv'\n",
    "s_t = pd.read_csv(os.path.join(os.getcwd() , \"outputs\", newfname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601e25b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# expanding pipeline for two predictors? mainly loss is impt, latency less so\n",
    "X, y = s_t[comb1[4]], s_t['loss']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                   random_state=0)\n",
    "pipe = Pipeline([('scaler', StandardScaler()), ('svc', GradientBoostingRegressor())])\n",
    " # The pipeline can be used as any other estimator\n",
    "# and avoids leaking the test set into the train set\n",
    "\n",
    "\n",
    "clf = GridSearchCV(GradientBoostingClassifier(), parameters,scoring=scoring,refit=False,cv=2, n_jobs=-1)\n",
    "\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "p = pipe.predict(X_test)\n",
    "mean_squared_error(y_test, p)\n",
    "#pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242447c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02dba4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_detailed_bytes(df, col='1->2Bytes', rollsec=10):\n",
    "    rollcolor = '#6c2b6d'\n",
    "    detailcolor = '#e98d6b'\n",
    "    \n",
    "    ax = plt.figure(figsize=(18,8))\n",
    "    df[col].plot(title=f'{col}/s Rate', color=detailcolor)\n",
    "    df[col].rolling(rollsec).mean().bfill().plot(color=rollcolor)\n",
    "    plt.axvline(x=180, color='r')\n",
    "    for i in df[df['event'] == 'drop'].index:\n",
    "        plt.axvline(x=i, color='y', alpha=.45)\n",
    "    custom_lines = [Line2D([0], [0], color=detailcolor, lw=2),\n",
    "        Line2D([0], [0], color=rollcolor, lw=2),\n",
    "        Line2D([0], [0], color='y', lw=2, alpha=0.45),\n",
    "        Line2D([0], [0], color='r', lw=2)]\n",
    "    plt.legend(custom_lines, \n",
    "               [f'{col} per Second', f'{col} per Second ({rollsec}s rolling avg)', 'Packet drop', '180s Mark'], \n",
    "               loc='upper right', framealpha=1);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
