{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1658c719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making changes to tempdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4eb17fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import sys\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from os import listdir\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.datasets import make_hastie_10_2\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dbd6c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, 'src')\n",
    "from helper import *\n",
    "from eda import *\n",
    "from train import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf1b6dd",
   "metadata": {},
   "source": [
    "### etl (new readfilerun and gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56b66dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readfilerun(run_, output_dir): # test_tempdata, tempdata\n",
    "    outdir = os.path.join(os.getcwd() , run_, output_dir)\n",
    "    names = listdir(run_) # all filenames in data\n",
    "    daneruns = [x for x in names if not 'losslog' in x]\n",
    "    daneruns = [ filename for filename in daneruns if filename.endswith('.csv') ]\n",
    "    \n",
    "    # daneruns = ['data/20220116T055105_20-100-true-20-100-iperf.csv', 'data/20220116T055942_20-250-true-20-250-iperf.csv']\n",
    "    losslogs = [x for x in names if 'losslog' in x]\n",
    "    #print(losslogs)\n",
    "    for count, run in enumerate(daneruns):\n",
    "        print(count)\n",
    "        # print(run) #for debug\n",
    "        #curr_losslog = losslogs[count] # \n",
    "       \n",
    "        print(\"run: \", run)\n",
    "        run_labels = run.split('_')[1].split('.')[0].split('-')\n",
    "        #print(\"run_labels:\", run_labels)\n",
    "        temp_label_str = '-'.join(run_labels[:-1]) \n",
    "        #print(temp_label_str)\n",
    "        \n",
    "        \n",
    "        losslog = f'{run_}/losslog-{temp_label_str}.csv' #losslog filename str\n",
    "\n",
    "        print(losslog)\n",
    "        run_df = pd.read_csv(f'{run_}/{run}')\n",
    "        losslog_df = pd.read_csv(losslog, header=None).rename(\n",
    "            columns={0:'event', 1:'drop_unix', 2:'IP1', 3:'Port1', 4:'IP2', 5:'Port2', 6:'Proto'})\n",
    "        losslog_df['Time'] = losslog_df['drop_unix'].astype(int)\n",
    "        losslog_df = losslog_df.groupby(['Time', 'IP1', 'Port1', 'IP2', 'Port2', 'Proto']).agg(lambda x: ';'.join(x.astype(str))).reset_index()\n",
    "        \n",
    "        df = pd.merge(run_df, losslog_df, on=['Time', 'IP1', 'Port1', 'IP2', 'Port2', 'Proto'], how=\"left\") # merge on fivetuple key\n",
    "        # df.fillna(inplace=True, value=-1) #TODO plan implementation of dealing with null values\n",
    "        # df['event'] =  # TODO change to 3 different profiles: no drop, drop, and switch event\n",
    "        df = df[df['Proto'] == df['Proto'].mode()[0]] # selects relevant non ipv6 int(connection\n",
    "        \n",
    "        ## adding labels\n",
    "        df['latency'] = int(run_labels[0])\n",
    "        df['loss'] = int(run_labels[1])\n",
    "        df['later_latency'] = int(run_labels[3])\n",
    "        df['later_loss'] = int(run_labels[4])\n",
    "        df['deterministic'] = bool(run_labels[2])\n",
    "        \n",
    "        #TODO future implementation of boolean flag for when the switch happens so we know when to use later lat/loss\n",
    "        \n",
    "        df.to_csv(f'{outdir}/labeled-from-{run_}_{temp_label_str}.csv') # save to temporary output directory: just merging takes a bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d520bfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_csv(lst, filepth):\n",
    "    '''takes list of pandas dataframes with similar column structure and outputs them to a single folder'''\n",
    "    lst[0].to_csv(filepth, index=False)\n",
    "    for i in range(1, len(lst)):\n",
    "        lst[i].to_csv(filepth, index=False, header=False, mode='a')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f602f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_helper(cond, window_start):\n",
    "    unseen = \"\"\n",
    "    if cond == 'seen': \n",
    "        print(\"subset of seen data\")\n",
    "    if cond == 'unseen': \n",
    "        print(\"subset of un seen data\")\n",
    "        unseen = \"unseen\"\n",
    "    \n",
    "    window = 8 # 8 second window\n",
    "    window_end = window_start + window\n",
    "    \n",
    "    tempdatafiles = listdir('data/tempdata')\n",
    "    fnames = [ filename for filename in tempdatafiles if filename.endswith(\".csv\" ) ]\n",
    "    \n",
    "    datasubset = []\n",
    "    for j in fnames:\n",
    "        fileloc = os.path.join(os.getcwd(), 'data', \"tempdata\", j)\n",
    "        print(fileloc)\n",
    "        \n",
    "        scaled = time(pd.read_csv(fileloc))\n",
    "        scaled['total_pkts'] = scaled['1->2Pkts'] + scaled['2->1Pkts'] # combining packets\n",
    "        scaled['total_bytes'] = scaled['1->2Bytes'] + scaled['2->1Bytes'] # combining bytes\n",
    "        scaled_subset = scaled.iloc[window_start: window_end]\n",
    "        datasubset.append(scaled_subset)\n",
    "        \n",
    "    path =  os.path.join(os.getcwd() , \"outputs\")\n",
    "    outname = unseen +  \"combined_subset\" + str(window_start) + \".csv\"\n",
    "    print(outname)\n",
    "    list_to_csv( datasubset, os.path.join(path, outname))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7340251f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen(cond , subset):\n",
    "    unseen = \"\"\n",
    "    if cond == 'seen': \n",
    "        print(\"transforming seen data\")\n",
    "    if cond == 'unseen': \n",
    "        print(\"transforming un seen data\")\n",
    "        unseen = \"unseen\"\n",
    "    tempdatafiles = listdir('data/tempdata')\n",
    "    if unseen == 'unseen': \n",
    "        tempdatafiles = listdir('test/test_tempdata')\n",
    "        \n",
    "    fnames = [ filename for filename in tempdatafiles if filename.endswith(\".csv\" ) ]\n",
    "    \n",
    "    data, datasubset, transformed  = [], [], []\n",
    "    for j in fnames:\n",
    "        loc = os.path.join(os.getcwd(), 'data', \"tempdata\", j)\n",
    "        if unseen == 'unseen': \n",
    "            loc = os.path.join(os.getcwd(), 'test', \"test_tempdata\", j)\n",
    "            \n",
    "        print(loc)\n",
    "        df_cols = genfeat(pd.read_csv(loc))\n",
    "        \n",
    "        #data\n",
    "        time_scaled = time(df_cols)\n",
    "        data.append(time_scaled)\n",
    "        \n",
    "        #subset\n",
    "#         df_mid = time_scaled.iloc[60:60+subset]\n",
    "#         datasubset.append(df_mid)\n",
    "\n",
    "        #transformed\n",
    "        f_df = agg10(df_cols)\n",
    "        transformed.append(f_df)\n",
    "        \n",
    "    # makes paths\n",
    "    path = os.path.join(os.getcwd() , \"outputs\", \"gen_temp\")\n",
    "    path2 = os.path.join(os.getcwd() , \"outputs\")\n",
    "    \n",
    "    list_to_csv(data, os.path.join(path2, unseen + \"combined_all.csv\"))\n",
    "    #print('combined_all_finished', sep=' ')\n",
    "#     list_to_csv(datasubset, os.path.join(path2, unseen + \"combined_subset_6068.csv\"))\n",
    "    #print('combined_subset_finished', sep=' ')\n",
    "    list_to_csv(transformed, os.path.join(path2, unseen +  \"combined_transform.csv\"))\n",
    "    #print('transformed_finished', sep=' ')\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81028c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genviz(cond, fname, subset):\n",
    "    unseen = \"\"\n",
    "    if cond == 'seen': \n",
    "        print(\"transforming seen data\")\n",
    "    if cond == 'unseen': \n",
    "        print(\"transforming un seen data\")\n",
    "        unseen = \"unseen\"\n",
    "\n",
    "    data, datasubset, transformed  = [], [], []\n",
    "    #loc = os.path.join(os.getcwd(),\"data\", \"tempdata\", fname)\n",
    "    loc =  os.path.join(os.getcwd(),\"tempdata2\", fname)\n",
    "    \n",
    "    t = pd.read_csv(loc)\n",
    "    df_cols = genfeat(t)\n",
    "    print(fname)\n",
    "    run_labels = fname.split('_')[1].split('.')[0].split('-')\n",
    "    print(run_labels)\n",
    "\n",
    "    #data\n",
    "    time_scaled = time(df_cols)\n",
    "    data.append(time_scaled)\n",
    "\n",
    "    #subset\n",
    "    df_mid = time_scaled.iloc[:subset]\n",
    "    datasubset.append(df_mid)\n",
    "\n",
    "    #transformed\n",
    "    f_df = agg10(df_cols)\n",
    "    transformed.append(f_df)\n",
    "    \n",
    "    path = os.path.join(os.getcwd() , \"outputs\", \"gen_temp\")\n",
    "    path2 = os.path.join(os.getcwd() , \"outputs\")\n",
    "    label = run_labels[0] + '-' + run_labels[1] +  '__' + run_labels[3] + '-' + run_labels[4]\n",
    "    temp_data = pd.concat(data , ignore_index=True)#.reset_index(drop = True)\n",
    "    temp_data.to_csv(os.path.join(path2, unseen + \"s_all_\" + label + \".csv\"), index = False)\n",
    "    \n",
    "    temp_subset = pd.concat(datasubset , ignore_index=True)\n",
    "    temp_subset.to_csv(os.path.join(path2, unseen +  \"s_subset_\" + label + \".csv\"), index = False)\n",
    "    \n",
    "    temp_t = pd.concat(transformed, ignore_index=True)  \n",
    "    temp_t.to_csv(os.path.join(path2, unseen +  \"s_transform_\" + label + \".csv\"), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec62b82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "61f89425",
   "metadata": {},
   "source": [
    "#### eda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1af48433",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_eda(cond, lst, filen1, filen2, filen3):\n",
    "    unseen = ''\n",
    "    if cond =='unseen': \n",
    "        unseen = 'unseen'\n",
    "    \n",
    "    fpath1 = os.path.join(os.getcwd() , \"outputs\", unseen + filen1)\n",
    "    df_1 = pd.read_csv(fpath1)\n",
    "    fpath2 = os.path.join(os.getcwd() , \"outputs\", unseen + filen2)\n",
    "    df_2 = pd.read_csv(fpath2)\n",
    "    fpath3 = os.path.join(os.getcwd() , \"outputs\", unseen + filen3)\n",
    "    df_3 = pd.read_csv(fpath3)\n",
    "    \n",
    "    plottogether(cond, lst, df_1, filen1.strip(\".csv\")) # trends over subset\n",
    "    plottogether(cond, lst, df_3, filen3.strip(\".csv\")) # trends over entire data\n",
    "    plotloss(cond, df_2)\n",
    "\n",
    "    plot_correlation_matrix(cond, df_2) # correlation matrix\n",
    "    plotlongest(df_3, cond, 600, 1400)\n",
    "    # below makes rest of visualizations\n",
    "    plotbytes(df_3, 600, 1400, 200, 200)\n",
    "    #plot_detailed_bytes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdddc05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28eb31ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overlaying model predictions and plotting detailed bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b510eac4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30152c8c",
   "metadata": {},
   "source": [
    "#### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2cb10284",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_feat(cond, df, cols, p, df_u): \n",
    "    unseen = ''\n",
    "    if cond =='unseen': \n",
    "        unseen = 'unseen'\n",
    "    # col is feauture comb\n",
    "    # p is for loss or latency   1: loss  # 2 : latency\n",
    "    X = df[cols]\n",
    "    \n",
    "    X2 = df_u[cols]\n",
    "\n",
    "    if p == 1:  # flag found in test_mse\n",
    "        y = df.loss\n",
    "        y2 = df_u.loss\n",
    "    if p == 2: \n",
    "        y = df.latency\n",
    "        y2 = df_u.latency\n",
    "        \n",
    "    # randomly split into train and test sets, test set is 80% of data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "    if unseen == 'unseen': \n",
    "        X_test = X2\n",
    "        y_test = y2\n",
    "    \n",
    "    clf = DecisionTreeRegressor()\n",
    "    clf = clf.fit(X_train,y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    acc1 = mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "    clf2 = RandomForestRegressor(n_estimators=10)\n",
    "    clf2 = clf2.fit(X_train,y_train)\n",
    "    y_pred2 = clf2.predict(X_test)\n",
    "    acc2= mean_squared_error(y_test, y_pred2)\n",
    "    \n",
    "    clf3 = ExtraTreesRegressor(n_estimators=10)\n",
    "    clf3 = clf3.fit(X_train,y_train)\n",
    "    y_pred3 = clf3.predict(X_test)\n",
    "    acc3= mean_squared_error(y_test, y_pred3)\n",
    "    \n",
    "    pca = PCA() \n",
    "    X_transformed = pca.fit_transform(X_train) \n",
    "    cl = DecisionTreeRegressor() \n",
    "    cl.fit(X_transformed, y_train)\n",
    "    newdata_transformed = pca.transform(X_test)\n",
    "    y_pred4 = cl.predict(newdata_transformed)\n",
    "    acc4 = mean_squared_error(y_test, y_pred4)\n",
    "    \n",
    "    clf_gbc = GradientBoostingRegressor(random_state=0)\n",
    "    clf_gbc.fit(X_train, y_train)\n",
    "    y_pred5 = clf_gbc.predict(X_test)\n",
    "    acc5 = mean_squared_error(y_test, y_pred5) \n",
    "    return [acc1, acc2, acc3, acc4, acc5]\n",
    "\n",
    "\n",
    "def test_mse(cond, all_comb1, all_comb2):\n",
    "    unseen = ''\n",
    "    if cond =='unseen': \n",
    "        unseen = 'unseen'\n",
    "    filedir_unseen = os.path.join(os.getcwd(), \"outputs\", unseen + \"combined_transform.csv\")\n",
    "    df_unseen = pd.read_csv(filedir_unseen)\n",
    "    filedir = os.path.join(os.getcwd(), \"outputs\", \"combined_transform.csv\")\n",
    "    df = pd.read_csv(filedir)\n",
    "    \n",
    "    all_comb1 = pd.Series(all_comb1).apply(lambda x: list(x))\n",
    "    all_comb2 = pd.Series(all_comb2).apply(lambda x: list(x))\n",
    "    \n",
    "    dt = []\n",
    "    rf = []\n",
    "    et = []\n",
    "    pca = []\n",
    "    gbc = []\n",
    "    for i in all_comb1:\n",
    "        acc_loss = test_feat(cond, df, i, 1, df_unseen)\n",
    "        dt.append(acc_loss[0])  \n",
    "        rf.append(acc_loss[1])  \n",
    "        et.append(acc_loss[2])   \n",
    "        pca.append(acc_loss[3])   \n",
    "        gbc.append(acc_loss[4])\n",
    "        \n",
    "    # optimze by adding a flag called losslat to avoid making two dataframes of results\n",
    "    dt2 = []\n",
    "    rf2 = []\n",
    "    et2 = []\n",
    "    pca2 = []\n",
    "    gbc2 = []\n",
    "    for i in all_comb2:\n",
    "        # 1 = loss\n",
    "        # 2 = latency\n",
    "        acc_latency = test_feat(cond, df, i, 2, df_unseen)\n",
    "        dt2.append(acc_latency[0])\n",
    "        rf2.append(acc_latency[1])\n",
    "        et2.append(acc_latency[2]) \n",
    "        pca2.append(acc_latency[3])\n",
    "        gbc2.append(acc_latency[4])\n",
    "        \n",
    "    dict1 = pd.DataFrame({'feat': all_comb1, 'dt': dt, 'rf': rf, 'et': et, 'pca': pca, 'gbc': gbc})\n",
    "    dict2 = pd.DataFrame({'feat2': all_comb2, 'dt2': dt2, 'rf2': rf2, 'et2': et2, 'pca2': pca2, 'gbc2': gbc2})\n",
    "    \n",
    "    path = os.path.join(os.getcwd() , \"outputs\")\n",
    "    dict1.to_csv(os.path.join(path, unseen + \"feat_df1.csv\"), index = False)\n",
    "    dict2.to_csv(os.path.join(path, unseen + \"feat_df2.csv\"), index = False)\n",
    "\n",
    "\n",
    "def best_performance(cond):\n",
    "    unseen = ''\n",
    "    if cond == 'unseen': \n",
    "        unseen = 'unseen'\n",
    "    #print(\"finding best loss performance\")\n",
    "    filedir1 = os.path.join(os.getcwd(), \"outputs\", unseen + \"feat_df1.csv\")\n",
    "    df1 = pd.read_csv(filedir1)\n",
    "    print( \"\\n\")\n",
    "    print(\"Loss Performance sorted from lowest to highest\", \"\\n\")\n",
    "    print(df1.sort_values(by=['dt', 'rf', 'et', 'pca'], ascending = True)[:5], \"\\n\")\n",
    "    \n",
    "    #print(\"finding best latency performance\")\n",
    "    filedir2 = os.path.join(os.getcwd(), \"outputs\", unseen + \"feat_df2.csv\")\n",
    "    df2 = pd.read_csv(filedir2)\n",
    "    print( \"\\n\")\n",
    "    print(\"Latency Performance sorted from lowest to highest\", \"\\n\")\n",
    "    print(df2.sort_values(by=['dt2', 'rf2', 'et2', 'pca2'], ascending = True)[:5], \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48801d7b",
   "metadata": {},
   "source": [
    "#### main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc580300",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(targets):\n",
    "\n",
    "    transform_config = json.load(open('config/transform.json'))\n",
    "    columns = json.load(open('config/columns.json'))\n",
    "    eda_config = json.load(open('config/eda.json'))\n",
    "    all_config = json.load(open(\"config/all.json\"))\n",
    "\n",
    "    test_unseen = 'unseen'\n",
    "    test_seen = 'seen'\n",
    "    \n",
    "    cond1 = True\n",
    "    cond2 = False\n",
    "\n",
    "    if 'data' in targets:\n",
    "        \"\"\"generating feat from unseen and seen data\"\"\"\n",
    "        readfilerun('data', 'tempdata') \n",
    "        readfilerun('test', 'test_tempdata') \n",
    "        gen(test_seen, **transform_config)\n",
    "        gen(test_unseen, **transform_config)\n",
    "\n",
    "    if 'eda' in targets:  \n",
    "#         readfilerun('data', 'tempdata') \n",
    "#         gen(test_seen, **transform_config)\n",
    "        main_eda(test_seen, [200, 200], **eda_config)\n",
    "        print(\"EDA saved to outputs/eda/ folder\")\n",
    "\n",
    "    if 'train' in targets:\n",
    "        \"trains tests in this target\"\n",
    "#         readfilerun('data', 'tempdata') \n",
    "#         gen(test_seen, **transform_config)\n",
    "                \n",
    "        comb1 = getAllCombinations(1)\n",
    "        comb2 = getAllCombinations(2)\n",
    "        \n",
    "        print(\"Testing on seen data: \")\n",
    "        test_mse(test_seen, comb1, comb2)\n",
    "        best_performance(test_seen)\n",
    "                        \n",
    "    if \"inference\" in targets: \n",
    "        print('tba')\n",
    "#         readfilerun('test', 'test_tempdata') \n",
    "#         gen(test_seen, **transform_config)\n",
    "#         gen(test_unseen, **transform_config)\n",
    "        \n",
    "        comb1 = getAllCombinations(1)\n",
    "        comb2 = getAllCombinations(2)\n",
    "        \n",
    "        print(\"Testing on unseen data: \")\n",
    "        test_mse(test_unseen, comb1, comb2)\n",
    "        best_performance(test_unseen)\n",
    "            \n",
    "    if \"test\" in targets: \n",
    "        \"\"\" runs all targets on sample data\"\"\"\n",
    "        print('tba')\n",
    "#         readfilerun('data', 'tempdata') \n",
    "#         gen(test_seen, **transform_config)\n",
    "#         gen(test_unseen, **transform_config)\n",
    "        \n",
    "#         main_eda(test_seen, **eda_config)\n",
    "#         print(\"EDA saved to outputs/eda/ folder\")\n",
    "        \n",
    "#         comb1 = getAllCombinations(1)\n",
    "#         comb2 = getAllCombinations(2)\n",
    "        \n",
    "#         print(\"Testing on seen data: \")\n",
    "#         test_mse(test_seen, comb1, comb2)\n",
    "#         best_performance(test_seen)\n",
    "        \n",
    "#         print(\"Testing on unseen data: \")\n",
    "#         test_mse(test_unseen, comb1, comb2)\n",
    "#         best_performance(test_unseen)\n",
    "        \n",
    "    if 'all' in targets: \n",
    "        print('tba')\n",
    "        \n",
    "# if __name__ == '__main__':\n",
    "\n",
    "#     targets = sys.argv[1:]\n",
    "#     main(targets)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "078c564e",
   "metadata": {},
   "source": [
    "path_ = os.path.join(os.getcwd() , \"outputs\")\n",
    "fp = os.path.join(path_, \"combined_all.csv\")\n",
    "fp2 = os.path.join(path_, \"combined_subset.csv\")\n",
    "dfall = pd.read_csv(fp)\n",
    "df_subset = pd.read_csv(fp2)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2d05c5c9",
   "metadata": {},
   "source": [
    "subset_helper('seen', 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3a82d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = ['data', 'eda', 'train', 'inference', 'test', 'all']\n",
    "# main(targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4be5bf55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "run:  20220117T055730_300-250-true-300-250-iperf.csv\n",
      "data/losslog-300-250-true-300-250.csv\n",
      "1\n",
      "run:  20220117T002516_100-15000-true-100-15000-iperf.csv\n",
      "data/losslog-100-15000-true-100-15000.csv\n",
      "2\n",
      "run:  20220118T022316_400-18000-true-400-18000-iperf.csv\n",
      "data/losslog-400-18000-true-400-18000.csv\n",
      "3\n",
      "run:  20220117T044411_250-15000-true-250-15000-iperf.csv\n",
      "data/losslog-250-15000-true-250-15000.csv\n",
      "4\n",
      "run:  20220118T011226_400-8000-true-400-8000-iperf.csv\n",
      "data/losslog-400-8000-true-400-8000.csv\n",
      "5\n",
      "run:  20220117T015822_200-100-true-200-100-iperf.csv\n",
      "data/losslog-200-100-true-200-100.csv\n",
      "6\n",
      "run:  20220117T045523_250-17000-true-250-17000-iperf.csv\n",
      "data/losslog-250-17000-true-250-17000.csv\n",
      "7\n",
      "run:  20220117T002515_100-13000-true-100-13000-iperf.csv\n",
      "data/losslog-100-13000-true-100-13000.csv\n",
      "8\n",
      "run:  20220117T235852_400-2000-true-400-2000-iperf.csv\n",
      "data/losslog-400-2000-true-400-2000.csv\n",
      "9\n",
      "run:  20220117T085718_350-4000-true-350-4000-iperf.csv\n",
      "data/losslog-350-4000-true-350-4000.csv\n",
      "10\n",
      "run:  20220118T051503_450-16000-true-450-16000-iperf.csv\n",
      "data/losslog-450-16000-true-450-16000.csv\n",
      "11\n",
      "run:  20220117T075305_300-12000-true-300-12000-iperf.csv\n",
      "data/losslog-300-12000-true-300-12000.csv\n",
      "12\n",
      "run:  20220117T015822_150-20000-true-150-20000-iperf.csv\n",
      "data/losslog-150-20000-true-150-20000.csv\n",
      "13\n",
      "run:  20220118T092052_500-16000-true-500-16000-iperf.csv\n",
      "data/losslog-500-16000-true-500-16000.csv\n",
      "14\n",
      "run:  20220117T012117_150-10000-true-150-10000-iperf.csv\n",
      "data/losslog-150-10000-true-150-10000.csv\n",
      "15\n",
      "run:  20220118T090438_500-10000-true-500-10000-iperf.csv\n",
      "data/losslog-500-10000-true-500-10000.csv\n",
      "16\n",
      "run:  20220117T082105_300-20000-true-300-20000-iperf.csv\n",
      "data/losslog-300-20000-true-300-20000.csv\n",
      "17\n",
      "run:  20220116T072039_20-14000-true-20-14000-iperf.csv\n",
      "data/losslog-20-14000-true-20-14000.csv\n",
      "18\n",
      "run:  20220118T043107_450-2000-true-450-2000-iperf.csv\n",
      "data/losslog-450-2000-true-450-2000.csv\n",
      "19\n",
      "run:  20220118T050008_450-10000-true-450-10000-iperf.csv\n",
      "data/losslog-450-10000-true-450-10000.csv\n",
      "0\n",
      "run:  20220118T093101_500-20000-true-500-20000-iperf.csv\n",
      "test/losslog-500-20000-true-500-20000.csv\n",
      "1\n",
      "run:  20220118T090438_500-11000-true-500-11000-iperf.csv\n",
      "test/losslog-500-11000-true-500-11000.csv\n",
      "2\n",
      "run:  20220117T014837_150-17000-true-150-17000-iperf.csv\n",
      "test/losslog-150-17000-true-150-17000.csv\n",
      "3\n",
      "run:  20220117T032950_200-17000-true-200-17000-iperf.csv\n",
      "test/losslog-200-17000-true-200-17000.csv\n",
      "4\n",
      "run:  20220118T044758_450-8000-true-450-8000-iperf.csv\n",
      "test/losslog-450-8000-true-450-8000.csv\n",
      "5\n",
      "run:  20220117T020702_200-2000-true-200-2000-iperf.csv\n",
      "test/losslog-200-2000-true-200-2000.csv\n",
      "6\n",
      "run:  20220117T004058_150-100-true-150-100-iperf.csv\n",
      "test/losslog-150-100-true-150-100.csv\n",
      "7\n",
      "run:  20220117T043152_250-11000-true-250-11000-iperf.csv\n",
      "test/losslog-250-11000-true-250-11000.csv\n",
      "8\n",
      "run:  20220116T083553_50-500-true-50-500-iperf.csv\n",
      "test/losslog-50-500-true-50-500.csv\n",
      "9\n",
      "run:  20220118T091213_500-15000-true-500-15000-iperf.csv\n",
      "test/losslog-500-15000-true-500-15000.csv\n",
      "transforming seen data\n",
      "/home/ldiao/180b/temprepo/data/tempdata/labeled-from-data_100-15000-true-100-15000.csv\n",
      "/home/ldiao/180b/temprepo/data/tempdata/labeled-from-data_20-14000-true-20-14000.csv\n",
      "/home/ldiao/180b/temprepo/data/tempdata/labeled-from-data_450-16000-true-450-16000.csv\n",
      "/home/ldiao/180b/temprepo/data/tempdata/labeled-from-data_400-8000-true-400-8000.csv\n",
      "/home/ldiao/180b/temprepo/data/tempdata/labeled-from-data_150-10000-true-150-10000.csv\n",
      "/home/ldiao/180b/temprepo/data/tempdata/labeled-from-data_400-18000-true-400-18000.csv\n",
      "/home/ldiao/180b/temprepo/data/tempdata/labeled-from-data_350-4000-true-350-4000.csv\n",
      "/home/ldiao/180b/temprepo/data/tempdata/labeled-from-data_250-17000-true-250-17000.csv\n",
      "/home/ldiao/180b/temprepo/data/tempdata/labeled-from-data_100-13000-true-100-13000.csv\n",
      "/home/ldiao/180b/temprepo/data/tempdata/labeled-from-data_450-10000-true-450-10000.csv\n",
      "/home/ldiao/180b/temprepo/data/tempdata/labeled-from-data_450-2000-true-450-2000.csv\n",
      "/home/ldiao/180b/temprepo/data/tempdata/labeled-from-data_300-250-true-300-250.csv\n",
      "/home/ldiao/180b/temprepo/data/tempdata/labeled-from-data_500-16000-true-500-16000.csv\n",
      "/home/ldiao/180b/temprepo/data/tempdata/labeled-from-data_300-12000-true-300-12000.csv\n",
      "/home/ldiao/180b/temprepo/data/tempdata/labeled-from-data_500-10000-true-500-10000.csv\n",
      "/home/ldiao/180b/temprepo/data/tempdata/labeled-from-data_250-15000-true-250-15000.csv\n",
      "/home/ldiao/180b/temprepo/data/tempdata/labeled-from-data_400-2000-true-400-2000.csv\n",
      "/home/ldiao/180b/temprepo/data/tempdata/labeled-from-data_200-100-true-200-100.csv\n",
      "/home/ldiao/180b/temprepo/data/tempdata/labeled-from-data_150-20000-true-150-20000.csv\n",
      "/home/ldiao/180b/temprepo/data/tempdata/labeled-from-data_300-20000-true-300-20000.csv\n",
      "transforming un seen data\n",
      "/home/ldiao/180b/temprepo/test/test_tempdata/labeled-from-test_150-17000-true-150-17000.csv\n",
      "/home/ldiao/180b/temprepo/test/test_tempdata/labeled-from-test_50-500-true-50-500.csv\n",
      "/home/ldiao/180b/temprepo/test/test_tempdata/labeled-from-test_200-2000-true-200-2000.csv\n",
      "/home/ldiao/180b/temprepo/test/test_tempdata/labeled-from-test_500-15000-true-500-15000.csv\n",
      "/home/ldiao/180b/temprepo/test/test_tempdata/labeled-from-test_500-11000-true-500-11000.csv\n",
      "/home/ldiao/180b/temprepo/test/test_tempdata/labeled-from-test_500-20000-true-500-20000.csv\n",
      "/home/ldiao/180b/temprepo/test/test_tempdata/labeled-from-test_250-11000-true-250-11000.csv\n",
      "/home/ldiao/180b/temprepo/test/test_tempdata/labeled-from-test_450-8000-true-450-8000.csv\n",
      "/home/ldiao/180b/temprepo/test/test_tempdata/labeled-from-test_150-100-true-150-100.csv\n",
      "/home/ldiao/180b/temprepo/test/test_tempdata/labeled-from-test_200-17000-true-200-17000.csv\n"
     ]
    }
   ],
   "source": [
    "main(targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9aa4587d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all combinations generated\n",
      "all combinations generated\n",
      "Testing on seen data: \n",
      "\n",
      "\n",
      "Loss Performance sorted from lowest to highest \n",
      "\n",
      "                                          feat   dt   rf   et  pca  \\\n",
      "0                              ['total_bytes']  0.0  0.0  0.0  0.0   \n",
      "1               ['longest_seq', 'total_bytes']  0.0  0.0  0.0  0.0   \n",
      "2                              ['longest_seq']  0.0  0.0  0.0  0.0   \n",
      "3                 ['max_bytes', 'total_bytes']  0.0  0.0  0.0  0.0   \n",
      "4  ['max_bytes', 'longest_seq', 'total_bytes']  0.0  0.0  0.0  0.0   \n",
      "\n",
      "            gbc  \n",
      "0  39480.454884  \n",
      "1   6849.668570  \n",
      "2  74037.977881  \n",
      "3   7970.491391  \n",
      "4   7178.137420   \n",
      "\n",
      "\n",
      "\n",
      "Latency Performance sorted from lowest to highest \n",
      "\n",
      "                                       feat2  dt2  rf2  et2  pca2      gbc2\n",
      "0                             ['total_pkts']  0.0  0.0  0.0   0.0  8.072446\n",
      "1                ['total_pkts', 'number_ms']  0.0  0.0  0.0   0.0  0.527684\n",
      "2                              ['number_ms']  0.0  0.0  0.0   0.0  3.885670\n",
      "3               ['total_pkts', 'byte_ratio']  0.0  0.0  0.0   0.0  0.346163\n",
      "4  ['total_pkts', 'number_ms', 'byte_ratio']  0.0  0.0  0.0   0.0  0.538666 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "main(targets[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fab445c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tba\n",
      "all combinations generated\n",
      "all combinations generated\n",
      "Testing on unseen data: \n",
      "\n",
      "\n",
      "Loss Performance sorted from lowest to highest \n",
      "\n",
      "                             feat          dt          rf          et  \\\n",
      "5    ['longest_seq', 'max_bytes']  16516000.0  19570960.0  19095070.0   \n",
      "6                   ['max_bytes']  27316000.0  27316000.0  22892660.0   \n",
      "1  ['longest_seq', 'total_bytes']  52081250.0  51522540.0  36626390.0   \n",
      "2                 ['longest_seq']  57246000.0  57246000.0  53172000.0   \n",
      "3    ['max_bytes', 'total_bytes']  58142250.0  52761522.5  50753125.0   \n",
      "\n",
      "          pca           gbc  \n",
      "5  52925000.0  1.968377e+07  \n",
      "6  27316000.0  2.734223e+07  \n",
      "1  60946000.0  4.943433e+07  \n",
      "2  57246000.0  5.729378e+07  \n",
      "3  61142250.0  4.868972e+07   \n",
      "\n",
      "\n",
      "\n",
      "Latency Performance sorted from lowest to highest \n",
      "\n",
      "                                       feat2      dt2      rf2      et2  \\\n",
      "5                ['number_ms', 'byte_ratio']   4000.0   5737.5   5010.5   \n",
      "2                              ['number_ms']  10500.0  10500.0  11867.5   \n",
      "4  ['total_pkts', 'number_ms', 'byte_ratio']  11750.0  11262.5   7276.5   \n",
      "1                ['total_pkts', 'number_ms']  11750.0  12282.5  12775.4   \n",
      "6                             ['byte_ratio']  14690.0  14690.0   9530.6   \n",
      "\n",
      "      pca2          gbc2  \n",
      "5   2500.0   8340.122569  \n",
      "2  10500.0  10207.374359  \n",
      "4   8500.0   6338.029578  \n",
      "1   8750.0  10541.275133  \n",
      "6  14690.0  14493.972103   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "main(targets[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de163a5b",
   "metadata": {},
   "source": [
    "MAKING pipeline: , tst on data with change in loss later\n",
    "\n",
    "* https://scikit-learn.org/stable/tutorial/statistical_inference/putting_together.html\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\n",
    "* https://stackoverflow.com/questions/58781601/parameter-tuning-using-gridsearchcv-for-gradientboosting-classifier-in-python\n",
    "    \n",
    "    comb[some index]\n",
    "    \n",
    "    dt() - untrained\n",
    "    \n",
    "    dt( comb) - train, or grid search on it\n",
    "    \n",
    "    et() - \n",
    "    \n",
    "    plot them on top of eachother\n",
    "    \n",
    "    test(single dataset - aggregated over subset )# overserved or not\n",
    "    \n",
    "    plot the bytes, loss records (loss log), and expanded model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b252a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(os.getcwd() , \"outputs\")\n",
    "\n",
    "comb1 = getAllCombinations(1)\n",
    "comb2 = getAllCombinations(2)\n",
    "\n",
    "fname = 'labeled-from-data2_100-12000-true-100-12000.csv'\n",
    "genviz('seen', fname, 8)\n",
    "newfname = 's_transform_200-1400__200-1000.csv'\n",
    "s_t = pd.read_csv(os.path.join(os.getcwd() , 'outputs', newfname))\n",
    "\n",
    "bob = pd.read_csv(os.path.join(os.getcwd() , \"tempdata2\", fname))\n",
    "bob['Seconds'] = bob['Time'] - min(bob['Time'])\n",
    "\n",
    "bob2 = pd.read_csv(os.path.join(os.getcwd() , 'outputs', newfname))\n",
    "\n",
    "X, y = s_t[comb1[4]], s_t['loss']\n",
    "\n",
    "# combined csv\n",
    "X_all = pd.read_csv(os.path.join(os.getcwd() , 'outputs', 'combined_transform.csv'))\n",
    "y_all = X_all['loss']\n",
    "\n",
    "# traintestsplit\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all[comb1[4]], y_all,\n",
    "                                                   random_state=0)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6ab373fc",
   "metadata": {},
   "source": [
    ">>> from sklearn import svm, datasets\n",
    ">>> from sklearn.model_selection import GridSearchCV\n",
    ">>> iris = datasets.load_iris()\n",
    ">>> parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
    ">>> svc = svm.SVC()\n",
    ">>> clf = GridSearchCV(svc, parameters)\n",
    ">>> clf.fit(iris.data, iris.target)\n",
    "GridSearchCV(estimator=SVC(),\n",
    "             param_grid={'C': [1, 10], 'kernel': ('linear', 'rbf')})\n",
    ">>> sorted(clf.cv_results_.keys())\n",
    "['mean_fit_time', 'mean_score_time', 'mean_test_score',...\n",
    " 'param_C', 'param_kernel', 'params',...\n",
    " 'rank_test_score', 'split0_test_score',...\n",
    " 'split2_test_score', ...\n",
    " 'std_fit_time', 'std_score_time', 'std_test_score']"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c815ed22",
   "metadata": {},
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "#creating Scoring parameter: \n",
    "scoring = {'mse': make_scorer(mean_squared_error)\n",
    "          }\n",
    "# feature paramter??\n",
    "\n",
    "# Define a pipeline to search for the best combination of PCA truncation\n",
    "# and classifier regularization.\n",
    "pca = PCA()\n",
    "# Define a Standard Scaler to normalize inputs\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# set the tolerance to a large value to make the example faster\n",
    "gradientbooster = GradientBoostingRegressor()\n",
    "# depth and length?\n",
    "pipe = Pipeline(steps=[(\"scaler\", scaler), (\"pca\", pca), (\"gbt\", gradientbooster)])\n",
    "\n",
    "X_digits, y_digits = X_all[comb1[4]], y_all\n",
    "# Parameters of pipelines can be set using ‘__’ separated parameter names:\n",
    "param_grid = {\n",
    "    \"pca__n_components\": [5, 15, 30, 45, 60],\n",
    "    \"gbt__max_depth\": [3, 6, 9],\n",
    "}\n",
    "search = GridSearchCV(pipe, param_grid, n_jobs=2,scoring=scoring, refit= False)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1c1acce5",
   "metadata": {},
   "source": [
    "X_digits.head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d5e114a5",
   "metadata": {},
   "source": [
    "print(X_digits.info())\n",
    "print(X_digits.info())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d3456ab1",
   "metadata": {},
   "source": [
    "search.fit(X_digits, y_digits)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "255d6c59",
   "metadata": {},
   "source": [
    "\n",
    "print(\"Best parameter (CV score=%0.3f):\" % search.best_score)\n",
    "print(search.best_params)\n",
    "\n",
    "# Plot the PCA spectrum\n",
    "pca.fit(X_digits)\n",
    "\n",
    "fig, (ax0, ax1) = plt.subplots(nrows=2, sharex=True, figsize=(6, 6))\n",
    "ax0.plot(\n",
    "    np.arange(1, pca.n_components_ + 1), pca.explained_variance_ratio_, \"+\", linewidth=2\n",
    ")\n",
    "ax0.set_ylabel(\"PCA explained variance ratio\")\n",
    "\n",
    "ax0.axvline(\n",
    "    search.best_estimator.named_steps[\"pca\"].n_components,\n",
    "    linestyle=\":\",\n",
    "    label=\"n_components chosen\",\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cbb570d2",
   "metadata": {},
   "source": [
    "! conda update -n base conda"
   ]
  },
  {
   "cell_type": "raw",
   "id": "27e7df1f",
   "metadata": {},
   "source": [
    "! conda update scikit-learn"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2cac98aa",
   "metadata": {},
   "source": [
    "search"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2d527176",
   "metadata": {},
   "source": [
    "search.get_params"
   ]
  },
  {
   "cell_type": "raw",
   "id": "839ed0e3",
   "metadata": {},
   "source": [
    "search."
   ]
  },
  {
   "cell_type": "raw",
   "id": "2e62300c",
   "metadata": {},
   "source": [
    "# expanding pipeline for two predictors? mainly loss is impt, latency less so\n",
    "pipe = Pipeline([('scaler', StandardScaler()), ('svc', RandomForestRegressor())])\n",
    "pipe.fit(X_train, y_train)\n",
    "p = pipe.predict(X_test)\n",
    "p_2 = pipe.predict(X)\n",
    "mean_squared_error(y_test, p) #pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240724c7",
   "metadata": {},
   "source": [
    "#### new plot (overlay bytes and preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1d7233",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small = pd.DataFrame(p_2).reset_index()\n",
    "df_small['index'] = df_small['index'].apply(lambda x: list(range(0, 17)))\n",
    "#print(df_small)\n",
    "df_small = df_small.explode('index').reset_index().rename(columns={\"index\": \"Seconds\", 0: \"loss\"})\n",
    "overlay = pd.DataFrame(df_small[['loss', 'Seconds']])\n",
    "overlay_17 = overlay[17:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd57c794",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay_17.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23294f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "bobble = pd.merge( overlay_17, bob, on='Seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02dba4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.lines import Line2D     \n",
    "def plot_detailed_bytes(df, col='1->2Bytes', rollsec=10, labelcol ='loss_x'):\n",
    "    rollcolor = '#6c2b6d'\n",
    "    detailcolor = '#e98d6b'\n",
    "    \n",
    "    ax = plt.figure(figsize=(18,8))\n",
    "    df[col].plot(title=f'{col}/s Rate', color=detailcolor)\n",
    "    df[col].rolling(rollsec).mean().bfill().plot(color=rollcolor)\n",
    "    plt.axvline(x=180, color='r')\n",
    "    \n",
    "    for i in df[df['event'] == 'drop'].index:\n",
    "        \n",
    "        plt.axvline(x=i, color='y', alpha=.45)\n",
    "    custom_lines = [Line2D([0], [0], color=detailcolor, lw=2),\n",
    "        Line2D([0], [0], color=rollcolor, lw=2),\n",
    "        Line2D([0], [0], color='y', lw=2, alpha=0.45),\n",
    "        Line2D([0], [0], color='r', lw=2)]\n",
    "    plt.legend(custom_lines, \n",
    "               [f'{col} per Second', f'{col} per Second ({rollsec}s rolling avg)', 'Packet drop', '180s Mark'], \n",
    "               loc='upper right', framealpha=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debffb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "bobble.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4c0536",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.lines\n",
    "plot_detailed_bytes(bobble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272a686d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf = GridSearchCV(GradientBoostingClassifier(), parameters,scoring=scoring,refit=False,cv=2, n_jobs=-1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
