{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e06bc3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making changes to tempdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e19c121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a working pipeline that you can apply and get a viz for every ten seconds.\n",
    "\n",
    "# refactor readfilerun to take in code properly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4eb17fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import sys\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from os import listdir\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.datasets import make_hastie_10_2\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import warnings\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4dbd6c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, 'src')\n",
    "from helper import *\n",
    "from eda import *\n",
    "from train import *\n",
    "from etl import *\n",
    "\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf1b6dd",
   "metadata": {},
   "source": [
    "### etl (new readfilerun and gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7ea5459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/raw/train', 'r/20220116T055105', '20-100-true-20-100-iperf.csv']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'data/raw/train_r/20220116T055105_20-100-true-20-100-iperf.csv'.split('_')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a9e043c2",
   "metadata": {},
   "source": [
    "df = readfilerun_simple('data/raw/train_r/20220116T055105_20-100-true-20-100-iperf.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56b66dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def readfilerun(run_):#, output_dir):\n",
    "#     outdir = os.path.join(os.getcwd() , \"data3\", \"tempdata3\")\n",
    "#     names = listdir('data3') # all filenames in data\n",
    "#     daneruns = [x for x in names if not 'losslog' in x]\n",
    "#     daneruns.remove('tempdata3')\n",
    "    \n",
    "#     # daneruns = ['data/20220116T055105_20-100-true-20-100-iperf.csv', 'data/20220116T055942_20-250-true-20-250-iperf.csv']\n",
    "#     losslogs = [x for x in names if 'losslog' in x]\n",
    "#     #print(losslogs)\n",
    "#     for count, run in enumerate(daneruns):\n",
    "#         print(count)\n",
    "#         # print(run) #for debug\n",
    "#         curr_losslog = losslogs[count]\n",
    "#         print(\"run: \", run)\n",
    "#         run_labels = run.split('_')[1].split('.')[0].split('-')\n",
    "#         print(\"run_labels:\", run_labels)\n",
    "#         temp_label_str = '-'.join(run_labels) \n",
    "#         #print(temp_label_str)\n",
    "#         losslog = f'data3/{curr_losslog}' #losslog filename str\n",
    "#         #print(f'data3/{run}')\n",
    "#         #print(losslog)\n",
    "#         run_df = pd.read_csv(f'data3/{run}')\n",
    "#         losslog_df = pd.read_csv(losslog, header=None).rename(\n",
    "#             columns={0:'event', 1:'drop_unix', 2:'IP1', 3:'Port1', 4:'IP2', 5:'Port2', 6:'Proto'})\n",
    "#         losslog_df['Time'] = losslog_df['drop_unix'].astype(int)\n",
    "#         losslog_df = losslog_df.groupby(['Time', 'IP1', 'Port1', 'IP2', 'Port2', 'Proto']).agg(lambda x: ';'.join(x.astype(str))).reset_index()\n",
    "#         df = pd.merge(run_df, losslog_df, on=['Time', 'IP1', 'Port1', 'IP2', 'Port2', 'Proto'], how=\"left\") # merge on fivetuple key\n",
    "#         # df.fillna(inplace=True, value=-1) #TODO plan implementation of dealing with null values\n",
    "#         # df['event'] =  # TODO change to 3 different profiles: no drop, drop, and switch event\n",
    "#         df = df[df['Proto'] == df['Proto'].mode()[0]] # selects relevant non ipv6 int(connection\n",
    "        \n",
    "#         ## adding labels\n",
    "#         df['latency'] = int(run_labels[0])\n",
    "#         df['loss'] = int(run_labels[1])\n",
    "#         df['later_latency'] = int(run_labels[3])\n",
    "#         df['later_loss'] = int(run_labels[4])\n",
    "#         df['deterministic'] = bool(run_labels[2])\n",
    "        \n",
    "#         #TODO future implementation of boolean flag for when the switch happens so we know when to use later lat/loss\n",
    "        \n",
    "#         df.to_csv(f'{outdir}/labeled-from-{run_}_{temp_label_str}.csv') # save to temporary output directory: just merging takes a bit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a743089b",
   "metadata": {},
   "source": [
    "NOTE TO SELF: this is wip on gen, you just copied lauras gen and are modifying it for your own use. Target for work tomorrow is getting it all to run using the main function, the model building should be trivial but gen is kicking your ass since its all the etl garbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7340251f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen(cond , tempdir, subset):\n",
    "    '''Generates transformed output data aggregated in 3 files.'''\n",
    "    unseen = \"\"\n",
    "    if cond == 'seen': \n",
    "        print(\"transforming seen data\")\n",
    "    if cond == 'unseen': \n",
    "        print(\"transforming un seen data\")\n",
    "        unseen = \"unseen\"\n",
    "    \n",
    "    tempdatafiles = 'data/temp/' + tempdir # temporary data directory for training model\n",
    "    tempagg = 'data/temp' # temporary data directory for training model\n",
    "    \n",
    "    # path = os.path.join(os.getcwd() , \"outputs\", \"gen_temp\")\n",
    "    # path2 = os.path.join(os.getcwd() , \"outputs\")\n",
    "    fnames = [ filename for filename in listdir(tempdatafiles) if filename.endswith(\".csv\" ) ]\n",
    "    \n",
    "    data, datasubset, transformed  = [], [], []\n",
    "    for j in fnames:\n",
    "        loc = os.path.join(os.getcwd(), 'data', \"temp/\" + tempdir, j)\n",
    "        #print(loc)\n",
    "        df_cols = genfeat(pd.read_csv(loc))\n",
    "        \n",
    "        #data\n",
    "        time_scaled = time(df_cols)\n",
    "        #print(time_scaled)\n",
    "        data.append(time_scaled)\n",
    "        \n",
    "        #subset\n",
    "        df_mid = time_scaled.iloc[60:60+subset]\n",
    "        datasubset.append(df_mid)\n",
    "\n",
    "        #transformed\n",
    "        f_df = agg10(df_cols)\n",
    "        transformed.append(f_df)\n",
    "        \n",
    "    # makes paths\n",
    "    path = os.path.join(os.getcwd() , \"outputs\", \"gen_temp\")\n",
    "    path2 = os.path.join(os.getcwd() , \"outputs\")\n",
    "    \n",
    "    list_to_csv(data, os.path.join(path2, unseen + \"combined_all.csv\"))\n",
    "    print('combined_finished', sep=' ')\n",
    "    list_to_csv(datasubset, os.path.join(path2, unseen + \"combined_subset_6068.csv\"))\n",
    "    print('combined_all_finished', sep=' ')\n",
    "    list_to_csv(transformed, os.path.join(path2, unseen +  \"combined_transform.csv\"))\n",
    "    print('transformed_finished', sep=' ')\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfcc6367",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_csv(lst, filepth):\n",
    "    '''takes list of pandas dataframes with similar column structure and outputs them to a single folder'''\n",
    "    lst[0].to_csv(filepth, index=False)\n",
    "    for i in range(1, len(lst)):\n",
    "        lst[i].to_csv(filepth, index=False, header=False, mode='a')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81028c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genviz(cond, fname, subset):\n",
    "    unseen = \"\"\n",
    "    if cond == 'seen': \n",
    "        print(\"transforming seen data\")\n",
    "    if cond == 'unseen': \n",
    "        print(\"transforming un seen data\")\n",
    "        unseen = \"unseen\"\n",
    "\n",
    "    data, datasubset, transformed  = [], [], []\n",
    "    loc = os.path.join(os.getcwd(),\"data3\", \"tempdata3\", fname)\n",
    "    \n",
    "    t = pd.read_csv(loc)\n",
    "    df_cols = genfeat(t)\n",
    "    print(fname)\n",
    "    run_labels = fname.split('_')[1].split('.')[0].split('-')\n",
    "    print(run_labels)\n",
    "\n",
    "    #data\n",
    "    time_scaled = time(df_cols)\n",
    "    data.append(time_scaled)\n",
    "\n",
    "    #subset\n",
    "    df_mid = time_scaled.iloc[:subset]\n",
    "    datasubset.append(df_mid)\n",
    "\n",
    "    #transformed\n",
    "    f_df = agg10(df_cols)\n",
    "    transformed.append(f_df)\n",
    "    \n",
    "    path = os.path.join(os.getcwd() , \"outputs\", \"gen_temp\")\n",
    "    path2 = os.path.join(os.getcwd() , \"outputs\")\n",
    "    label = run_labels[0] + '-' + run_labels[1] +  '__' + run_labels[3] + '-' + run_labels[4]\n",
    "    temp_data = pd.concat(data , ignore_index=True)#.reset_index(drop = True)\n",
    "    temp_data.to_csv(os.path.join(path2, unseen + \"s_all_\" + label + \".csv\"), index = False)\n",
    "    \n",
    "    temp_subset = pd.concat(datasubset , ignore_index=True)\n",
    "    temp_subset.to_csv(os.path.join(path2, unseen +  \"s_subset_\" + label + \".csv\"), index = False)\n",
    "    \n",
    "    temp_t = pd.concat(transformed, ignore_index=True)  \n",
    "    temp_t.to_csv(os.path.join(path2, unseen +  \"s_transform_\" + label + \".csv\"), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ec62b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_helper(ct, file_lst, subset, unseen):\n",
    "    \"\"\" \"\"\"\n",
    "    data, datasubset, transformed  = [], [], []\n",
    "    for j in file_lst:\n",
    "        loc = os.path.join(os.getcwd(),\"data3\",  \"tempdata3\", j)\n",
    "        print(loc)\n",
    "        df_cols = genfeat(pd.read_csv(loc))\n",
    "        \n",
    "        #data\n",
    "        time_scaled = time(df_cols)\n",
    "        data.append(time_scaled)\n",
    "        \n",
    "        #subset\n",
    "        df_mid = time_scaled.iloc[60: 60+subset]\n",
    "        datasubset.append(df_mid)\n",
    "\n",
    "        #transformed\n",
    "        f_df = agg10(df_cols)\n",
    "        transformed.append(f_df)\n",
    "\n",
    "    path = os.path.join(os.getcwd() , \"outputs\", \"gen_temp\")\n",
    "\n",
    "    temp_data = pd.concat(data , ignore_index=True)#.reset_index(drop = True)\n",
    "    temp_data.to_csv(os.path.join(path, unseen + \"temp_all_\" + str(ct) + \".csv\"), index = False)\n",
    "    \n",
    "    temp_subset = pd.concat(datasubset , ignore_index=True)\n",
    "    temp_subset.to_csv(os.path.join(path, unseen +  \"temp_subset_6068_\" + str(ct) + \".csv\"), index = False)\n",
    "    \n",
    "    temp_t = pd.concat(transformed, ignore_index=True)  \n",
    "    temp_t.to_csv(os.path.join(path, unseen +  \"temp_transform_\" + str(ct) + \".csv\"), index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f89425",
   "metadata": {},
   "source": [
    "#### eda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0fdddc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_eda(cond, lst, filen1, filen2, filen3):\n",
    "    unseen = ''\n",
    "    if cond =='unseen': \n",
    "        unseen = 'unseen'\n",
    "    \n",
    "    fpath1 = os.path.join(os.getcwd() , \"outputs\", unseen + filen1)\n",
    "    df_1 = pd.read_csv(fpath1)\n",
    "    fpath2 = os.path.join(os.getcwd() , \"outputs\", unseen + filen2)\n",
    "    df_2 = pd.read_csv(fpath2)\n",
    "    fpath3 = os.path.join(os.getcwd() , \"outputs\", unseen + filen3)\n",
    "    df_3 = pd.read_csv(fpath3)\n",
    "    \n",
    "    plottogether(cond, lst, df_1, filen1.strip(\".csv\")) # trends over subset\n",
    "    plottogether(cond, lst, df_3, filen3.strip(\".csv\")) # trends over entire data\n",
    "    plotloss(cond, df_2)\n",
    "\n",
    "    plot_correlation_matrix(cond, df_2) # correlation matrix\n",
    "    plotlongest(df_3, cond, 2000, 14000)\n",
    "    # below makes rest of visualizations\n",
    "    plotbytes(df_3, 2000, 14000, 200, 300)\n",
    "    #plot_detailed_bytes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28eb31ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overlaying model predictions and plotting detailed bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b510eac4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30152c8c",
   "metadata": {},
   "source": [
    "#### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2cb10284",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_feat(cond, df, cols, p, df_u): \n",
    "    unseen = ''\n",
    "    if cond =='unseen': \n",
    "        unseen = 'unseen'\n",
    "    # col is feauture comb\n",
    "    # p is for loss or latency   1: loss  # 2 : latency\n",
    "    X = df[cols]\n",
    "    \n",
    "    X2 = df_u[cols]\n",
    "\n",
    "    if p == 1:  # flag found in test_mse\n",
    "        y = df.loss\n",
    "        y2 = df_u.loss\n",
    "    if p == 2: \n",
    "        y = df.latency\n",
    "        y2 = df_u.latency\n",
    "        \n",
    "    # randomly split into train and test sets, test set is 80% of data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=1)\n",
    "\n",
    "    if unseen == 'unseen': \n",
    "        X_test = X2\n",
    "        y_test = y2\n",
    "    \n",
    "    clf = DecisionTreeRegressor()\n",
    "    clf = clf.fit(X_train,y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    #acc1 = mean_squared_error(y_test, y_pred)\n",
    "    acc1 = clf.score(X_test, y_test)\n",
    "    \n",
    "    clf2 = RandomForestRegressor(n_estimators=200, n_jobs = -1)\n",
    "    clf2 = clf2.fit(X_train,y_train)\n",
    "    y_pred2 = clf2.predict(X_test)\n",
    "    #acc2= mean_squared_error(y_test, y_pred2)\n",
    "    acc2 = clf2.score(X_test, y_test)\n",
    "    \n",
    "    clf3 = ExtraTreesRegressor(n_estimators=200, n_jobs = -1)\n",
    "    clf3 = clf3.fit(X_train,y_train)\n",
    "    y_pred3 = clf3.predict(X_test)\n",
    "    #acc3= mean_squared_error(y_test, y_pred3)\n",
    "    acc3 = clf3.score(X_test, y_test)\n",
    "    \n",
    "#     pca = PCA(n_components = 2) \n",
    "#     X_transformed = pca.fit_transform(X_train) \n",
    "#     clf4 = ExtraTreesRegressor(n_estimators=100, n_jobs = -1)\n",
    "#     clf4 = clf4.fit(X_transformed, y_train)\n",
    "#     newdata_transformed = pca.transform(X_test)\n",
    "#     y_pred4 = clf4.predict(newdata_transformed)\n",
    "#     #acc4 = mean_squared_error(y_test, y_pred4)\n",
    "#     acc4 = clf4.score(X_test, y_test)\n",
    "    \n",
    "    clf_gbc = GradientBoostingRegressor(random_state=0, max_depth = 6, n_estimators=200)\n",
    "    clf_gbc.fit(X_train, y_train)\n",
    "    y_pred5 = clf_gbc.predict(X_test)\n",
    "    #acc5 = mean_squared_error(y_test, y_pred5) \n",
    "    acc5 = clf_gbc.score(X_test, y_test)\n",
    "    return [acc1, acc2, acc3,  acc5]\n",
    "\n",
    "\n",
    "def test_mse(cond, all_comb1, all_comb2):\n",
    "    unseen = ''\n",
    "    if cond =='unseen': \n",
    "        unseen = 'unseen'\n",
    "    filedir_unseen = os.path.join(os.getcwd(), \"outputs\", unseen + \"combined_transform.csv\")\n",
    "    df_unseen = pd.read_csv(filedir_unseen)\n",
    "    filedir = os.path.join(os.getcwd(), \"outputs\", \"combined_transform.csv\")\n",
    "    df = pd.read_csv(filedir)\n",
    "    \n",
    "    all_comb1 = pd.Series(all_comb1).apply(lambda x: list(x))\n",
    "    all_comb2 = pd.Series(all_comb2).apply(lambda x: list(x))\n",
    "    \n",
    "    dt = []\n",
    "    rf = []\n",
    "    et = []\n",
    "    #pca = []\n",
    "    gbc = []\n",
    "    for i in all_comb1:\n",
    "        acc_loss = test_feat(cond, df, i, 1, df_unseen)\n",
    "        dt.append(acc_loss[0])  \n",
    "        rf.append(acc_loss[1])  \n",
    "        et.append(acc_loss[2])   \n",
    "        #pca.append(acc_loss[3])   \n",
    "        gbc.append(acc_loss[3])\n",
    "        \n",
    "    # optimze by adding a flag called losslat to avoid making two dataframes of results\n",
    "    dt2 = []\n",
    "    rf2 = []\n",
    "    et2 = []\n",
    "    #pca2 = []\n",
    "    gbc2 = []\n",
    "    for i in all_comb2:\n",
    "        # 1 = loss\n",
    "        # 2 = latency\n",
    "        acc_latency = test_feat(cond, df, i, 2, df_unseen)\n",
    "        dt2.append(acc_latency[0])\n",
    "        rf2.append(acc_latency[1])\n",
    "        et2.append(acc_latency[2]) \n",
    "        #pca2.append(acc_latency[3])\n",
    "        gbc2.append(acc_latency[3])\n",
    "        \n",
    "    dict1 = pd.DataFrame({'feat': all_comb1, 'dt': dt, 'rf': rf, 'et': et, 'gbc': gbc})\n",
    "    dict2 = pd.DataFrame({'feat2': all_comb2, 'dt2': dt2, 'rf2': rf2, 'et2': et2, 'gbc2': gbc2})\n",
    "    \n",
    "    path = os.path.join(os.getcwd() , \"outputs\")\n",
    "    dict1.to_csv(os.path.join(path, unseen + \"feat_df1.csv\"), index = False)\n",
    "    dict2.to_csv(os.path.join(path, unseen + \"feat_df2.csv\"), index = False)\n",
    "\n",
    "\n",
    "def best_performance(cond):\n",
    "    unseen = ''\n",
    "    if cond == 'unseen': \n",
    "        unseen = 'unseen'\n",
    "    #print(\"finding best loss performance\")\n",
    "    filedir1 = os.path.join(os.getcwd(), \"outputs\", unseen + \"feat_df1.csv\")\n",
    "    df1 = pd.read_csv(filedir1)\n",
    "    df1_round = df1.round(decimals = 3)\n",
    "    print( \"\\n\")\n",
    "    print(\"Loss Performance sorted from highest to lowest metric: r2\", \"\\n\")\n",
    "    print(df1_round.sort_values(by=['dt', 'rf', 'et', 'gbc'], ascending = False)[:5], \"\\n\")\n",
    "    \n",
    "    #print(\"finding best latency performance\")\n",
    "    filedir2 = os.path.join(os.getcwd(), \"outputs\", unseen + \"feat_df2.csv\")\n",
    "    df2 = pd.read_csv(filedir2)\n",
    "    df2_round = df2.round(decimals = 3)\n",
    "    print( \"\\n\")\n",
    "    print(\"Latency Performance sorted from highest to lowest metric: r2\", \"\\n\")\n",
    "    print(df2_round.sort_values(by=['dt2', 'rf2', 'et2', 'gbc2'], ascending = False)[:5], \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48801d7b",
   "metadata": {},
   "source": [
    "#### main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cc580300",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(targets):\n",
    "\n",
    "    transform_config = json.load(open('config/transform.json'))\n",
    "    columns = json.load(open('config/columns.json'))\n",
    "    eda_config = json.load(open('config/eda.json'))\n",
    "    all_config = json.load(open(\"config/all.json\"))\n",
    "\n",
    "    test_unseen = 'unseen'\n",
    "    test_seen = 'seen'\n",
    "    \n",
    "    cond1 = True\n",
    "    cond2 = False\n",
    "\n",
    "    if 'data' in targets:\n",
    "        \"\"\"generating feat from unseen and seen data\"\"\"\n",
    "        #readfilerun('data/raw/train_r', 'data/temp/tempdata_r') # TODO uncomment\n",
    "        #gen(test_seen, 'tempdata_r', **transform_config)\n",
    "        readfilerun('data/raw/train_c', 'data/temp/tempdata_c')\n",
    "        gen(test_unseen, 'tempdata_c', **transform_config)\n",
    "\n",
    "    if 'eda' in targets:  \n",
    "        # readfiledrun and gen for seen data, refer to data target\n",
    "        main_eda(test_seen, [200, 300], **eda_config)\n",
    "        print(\"EDA saved to outputs/eda/ folder\")\n",
    "\n",
    "    if 'train' in targets:\n",
    "        \"trains tests in this target\"\n",
    "        # readfiledrun and gen for seen data, refer to data target\n",
    "                \n",
    "        #comb1 = getAllCombinations(1)\n",
    "        #comb2 = getAllCombinations(2)\n",
    "        \n",
    "        #print(\"Testing on seen data: \")\n",
    "        #test_mse(test_seen, comb1, comb2)\n",
    "        best_performance(test_seen)\n",
    "                        \n",
    "    if \"inference\" in targets: \n",
    "        # readfiledrun and gen for unseen data, refer to data target\n",
    "        \n",
    "#         comb1 = getAllCombinations(1)\n",
    "#         comb2 = getAllCombinations(2)\n",
    "        \n",
    "#         print(\"Testing on unseen data: \")\n",
    "#         test_mse(test_unseen, comb1, comb2)\n",
    "        best_performance(test_unseen)\n",
    "            \n",
    "    if \"test\" in targets: \n",
    "        \"\"\" runs all targets on sample data\"\"\"\n",
    "        print('tba')\n",
    "        # readfilerun for seen an unseen data\n",
    "       \n",
    "        #  main_eda(test_seen, **eda_config)\n",
    "#          print(\"EDA saved to outputs/eda/ folder\")\n",
    "        \n",
    "#         comb1 = getAllCombinations(1)\n",
    "#         comb2 = getAllCombinations(2)\n",
    "        \n",
    "#         print(\"Testing on seen data: \")\n",
    "#         test_mse(test_seen, comb1, comb2)\n",
    "#         best_performance(test_seen)\n",
    "        \n",
    "#         print(\"Testing on unseen data: \")\n",
    "#         test_mse(test_unseen, comb1, comb2)\n",
    "#         best_performance(test_unseen)\n",
    "        \n",
    "    if 'all' in targets: \n",
    "        # refer to test target\n",
    "        print('tba')\n",
    "        \n",
    "# if __name__ == '__main__':\n",
    "\n",
    "#     targets = sys.argv[1:]\n",
    "#     main(targets)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "078c564e",
   "metadata": {},
   "source": [
    "path_ = os.path.join(os.getcwd() , \"outputs\")\n",
    "fp = os.path.join(path_, \"combined_all.csv\")\n",
    "fp2 = os.path.join(path_, \"combined_subset.csv\")\n",
    "dfall = pd.read_csv(fp)\n",
    "df_subset = pd.read_csv(fp2)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "00f3c7c7",
   "metadata": {},
   "source": [
    "readfilerun('data3')#, 'tempdata3') # takes a long time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f3a82d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = ['data', 'eda', 'train', 'inference', 'test', 'all']\n",
    "# main(targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9aa4587d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loss Performance sorted from highest to lowest metric: r2 \n",
      "\n",
      "                                                  feat     dt     rf     et  \\\n",
      "59   ['mean_tdelta', 'total_pkt_sizes', 'pkt sum', ...  0.720  0.759  0.747   \n",
      "91   ['mean_tdelta', 'total_pkts', 'total_pkt_sizes...  0.700  0.757  0.744   \n",
      "122  ['mean_tdelta', 'total_pkt_sizes', 'number_ms'...  0.664  0.752  0.739   \n",
      "93                         ['total_pkts', 'number_ms']  0.661  0.724  0.691   \n",
      "104  ['total_pkts_max', 'mean_tdelta', 'total_pkt_s...  0.659  0.791  0.797   \n",
      "\n",
      "       gbc  \n",
      "59   0.769  \n",
      "91   0.758  \n",
      "122  0.754  \n",
      "93   0.668  \n",
      "104  0.774   \n",
      "\n",
      "\n",
      "\n",
      "Latency Performance sorted from highest to lowest metric: r2 \n",
      "\n",
      "                                       feat2    dt2    rf2    et2   gbc2\n",
      "0                             ['byte_ratio']  1.000  1.000  1.000  1.000\n",
      "7                ['byte_ratio', 'pkt_ratio']  1.000  1.000  0.999  1.000\n",
      "1              ['byte_ratio', 'total_bytes']  0.983  0.982  0.978  0.978\n",
      "3                 ['2->1Pkts', 'byte_ratio']  0.983  0.981  0.985  0.983\n",
      "4  ['2->1Pkts', 'byte_ratio', 'total_bytes']  0.983  0.981  0.957  0.978 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "main(targets[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fe425e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loss Performance sorted from highest to lowest metric: r2 \n",
      "\n",
      "                                                 feat     dt     rf     et  \\\n",
      "56  ['total_pkts_max', 'mean_tdelta', 'total_pkt_s...  0.245  0.536  0.519   \n",
      "49  ['mean_tdelta', 'total_pkts_max', 'pkt sum', '...  0.237  0.520  0.515   \n",
      "88  ['total_pkts_max', 'mean_tdelta', 'total_pkt_s...  0.236  0.549  0.531   \n",
      "19  ['mean_tdelta', 'total_pkts_max', '2->1Bytes',...  0.202  0.554  0.555   \n",
      "89  ['total_pkts_max', '2->1Bytes', 'number_ms', '...  0.199  0.556  0.552   \n",
      "\n",
      "      gbc  \n",
      "56  0.429  \n",
      "49  0.428  \n",
      "88  0.450  \n",
      "19  0.514  \n",
      "89  0.506   \n",
      "\n",
      "\n",
      "\n",
      "Latency Performance sorted from highest to lowest metric: r2 \n",
      "\n",
      "                                                feat2    dt2    rf2    et2  \\\n",
      "30                                ['time_spread_min'] -2.275 -1.819 -2.132   \n",
      "58  ['total_bytes', '2->1Pkts', 'pkt_ratio', 'time... -4.169 -1.837 -1.546   \n",
      "55  ['pkt_ratio', 'total_bytes', 'time_spread_min'... -4.384 -1.814 -1.416   \n",
      "59  ['2->1Pkts', 'pkt_ratio', 'time_spread_min', '... -4.384 -1.844 -1.462   \n",
      "60     ['pkt_ratio', 'time_spread_min', 'max_tdelta'] -4.898 -1.232 -1.308   \n",
      "\n",
      "     gbc2  \n",
      "30 -1.707  \n",
      "58 -2.880  \n",
      "55 -2.639  \n",
      "59 -2.552  \n",
      "60 -1.750   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "main(targets[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d023030f",
   "metadata": {},
   "source": [
    "git add . |\n",
    "git commmit -m \"message\" |\n",
    "git pull origin main |\n",
    "git push |\n",
    "user, token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab445c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#listdir('data/raw/train_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac906670",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "label_col = 'latency'\n",
    "\n",
    "df = pd.read_csv(os.path.join(os.getcwd() , \"outputs\", 'combined_transform.csv'))\n",
    "\n",
    "indexcol = ['total_bytes','max_bytes','2->1Bytes','2->1Pkts','total_pkts', 'total_pkts_min', 'total_pkts_max', 'number_ms', 'pkt_ratio','time_spread', 'time_spread_min','time_spread_max','pkt sum','longest_seq', 'longest_seq_min', 'longest_seq_max','total_pkt_sizes','byte_ratio', 'mean_tdelta', 'max_tdelta']\n",
    "len(indexcol)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[[x for x in indexcol if x in df.columns]], df[label_col])\n",
    "# print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "etree = ExtraTreesRegressor(n_estimators=400, n_jobs=4)\n",
    "etreeft = etree.fit(X_train,y_train)\n",
    "\n",
    "y_pred3 = etree.predict(X_test)\n",
    "acc3= mean_squared_error(y_test, y_pred3)\n",
    "\n",
    "print(f'mse: {acc3}, r2: {etree.score(X_test, y_test)}')\n",
    "feat_imp = pd.Series(index=[x for x in indexcol if x in df.columns], \n",
    "          data=etree.feature_importances_).sort_values(ascending=False)\n",
    "feat_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b166aa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "label_col = 'loss'\n",
    "\n",
    "df = pd.read_csv(os.path.join(os.getcwd() , \"outputs\", 'combined_transform.csv'))\n",
    "\n",
    "indexcol = ['total_bytes','max_bytes','2->1Bytes','2->1Pkts','total_pkts', 'total_pkts_min', 'total_pkts_max', 'number_ms', 'pkt_ratio','time_spread', 'time_spread_min','time_spread_max','pkt sum','longest_seq', 'longest_seq_min', 'longest_seq_max','total_pkt_sizes','byte_ratio', 'mean_tdelta', 'max_tdelta']\n",
    "len(indexcol)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[[x for x in indexcol if x in df.columns]], df[label_col])\n",
    "# print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "etree = ExtraTreesRegressor(n_estimators=400, n_jobs=4)\n",
    "etreeft = etree.fit(X_train,y_train)\n",
    "\n",
    "y_pred3 = etree.predict(X_test)\n",
    "acc3= mean_squared_error(y_test, y_pred3)\n",
    "\n",
    "print(f'mse: {acc3}, r2: {etree.score(X_test, y_test)}')\n",
    "feat_imp = pd.Series(index=[x for x in indexcol if x in df.columns], \n",
    "          data=etree.feature_importances_).sort_values(ascending=False)\n",
    "feat_imp"
   ]
  },
  {
   "cell_type": "raw",
   "id": "79d30554",
   "metadata": {},
   "source": [
    "MAKING pipeline: , tst on data with change in loss later\n",
    "    \n",
    "    comb[some index]\n",
    "    \n",
    "    dt() - untrained\n",
    "    \n",
    "    dt( comb) - train, or grid search on it\n",
    "    \n",
    "    et() - \n",
    "    \n",
    "    plot them on top of eachother\n",
    "    \n",
    "    test(single dataset - aggregated over subset )# overserved or not\n",
    "    \n",
    "    plot the bytes, loss records (loss log), and expanded model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f16b215",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "path = os.path.join(os.getcwd() , \"outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f9419d",
   "metadata": {},
   "outputs": [],
   "source": [
    "comb1 = getAllCombinations(1)\n",
    "comb2 = getAllCombinations(2)\n",
    "comb1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cca963b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fname = 'labeled-from-data2_100-10000-true-100-10000.csv'\n",
    "genviz('seen', fname, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca742245",
   "metadata": {},
   "outputs": [],
   "source": [
    "newfname = 'combined_t.csv'\n",
    "s_t = pd.read_csv(os.path.join(os.getcwd() , \"outputs\", newfname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601e25b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# expanding pipeline for two predictors? mainly loss is impt, latency less so\n",
    "X, y = s_t[comb1[4]], s_t['loss']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                   random_state=0)\n",
    "pipe = Pipeline([('scaler', StandardScaler()), ('svc', GradientBoostingRegressor())])\n",
    " # The pipeline can be used as any other estimator\n",
    "# and avoids leaking the test set into the train set\n",
    "\n",
    "\n",
    "clf = GridSearchCV(GradientBoostingClassifier(), parameters,scoring=scoring,refit=False,cv=2, n_jobs=-1)\n",
    "\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "p = pipe.predict(X_test)\n",
    "mean_squared_error(y_test, p)\n",
    "#pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242447c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02dba4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_detailed_bytes(df, col='1->2Bytes', rollsec=10):\n",
    "    rollcolor = '#6c2b6d'\n",
    "    detailcolor = '#e98d6b'\n",
    "    \n",
    "    ax = plt.figure(figsize=(18,8))\n",
    "    df[col].plot(title=f'{col}/s Rate', color=detailcolor)\n",
    "    df[col].rolling(rollsec).mean().bfill().plot(color=rollcolor)\n",
    "    plt.axvline(x=180, color='r')\n",
    "    for i in df[df['event'] == 'drop'].index:\n",
    "        plt.axvline(x=i, color='y', alpha=.45)\n",
    "    custom_lines = [Line2D([0], [0], color=detailcolor, lw=2),\n",
    "        Line2D([0], [0], color=rollcolor, lw=2),\n",
    "        Line2D([0], [0], color='y', lw=2, alpha=0.45),\n",
    "        Line2D([0], [0], color='r', lw=2)]\n",
    "    plt.legend(custom_lines, \n",
    "               [f'{col} per Second', f'{col} per Second ({rollsec}s rolling avg)', 'Packet drop', '180s Mark'], \n",
    "               loc='upper right', framealpha=1);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
