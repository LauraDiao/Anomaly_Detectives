{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e06bc3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making changes to tempdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e19c121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a working pipeline that you can apply and get a viz for every ten seconds.\n",
    "\n",
    "# refactor readfilerun to take in code properly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4eb17fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import sys\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import time \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from os import listdir\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.datasets import make_hastie_10_2\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import warnings\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4dbd6c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "sys.path.insert(0, 'src')\n",
    "from helper import *\n",
    "from eda import *\n",
    "from train import *\n",
    "from etl import *\n",
    "\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48801d7b",
   "metadata": {},
   "source": [
    "#### main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cc580300",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(targets):\n",
    "\n",
    "    transform_config = json.load(open('config/transform.json'))\n",
    "    columns = json.load(open('config/columns.json'))\n",
    "    eda_config = json.load(open('config/eda.json'))\n",
    "    all_config = json.load(open(\"config/all.json\"))\n",
    "\n",
    "    test_unseen = 'unseen'\n",
    "    test_seen = 'seen'\n",
    "    \n",
    "    cond1 = True\n",
    "    cond2 = False\n",
    "\n",
    "    if 'data' in targets:\n",
    "        \"\"\"generating feat from unseen and seen data\"\"\"\n",
    "        readfilerun('data/raw/train_r', 'data/temp/tempdata_r') # TODO uncomment\n",
    "        gen(test_seen, 'tempdata_r', **transform_config)\n",
    "        readfilerun('data/raw/train_c', 'data/temp/tempdata_c')\n",
    "        gen(test_unseen, 'tempdata_c', **transform_config)\n",
    "\n",
    "    if 'eda' in targets:  \n",
    "        # readfiledrun and gen for seen data, refer to data target\n",
    "        main_eda(test_seen, [200, 300], **eda_config)\n",
    "        print(\"EDA saved to outputs/eda/ folder\")\n",
    "\n",
    "    if 'train' in targets:\n",
    "        \"trains tests in this target\"\n",
    "        # readfiledrun and gen for seen data, refer to data target\n",
    "                \n",
    "        #comb1 = getAllCombinations(1)\n",
    "        #comb2 = getAllCombinations(2)\n",
    "        \n",
    "        #print(\"Testing on seen data: \")\n",
    "        #test_mse(test_seen, comb1, comb2)\n",
    "        best_performance(test_seen)\n",
    "                        \n",
    "    if \"inference\" in targets: \n",
    "        # readfiledrun and gen for unseen data, refer to data target\n",
    "        \n",
    "#         comb1 = getAllCombinations(1)\n",
    "#         comb2 = getAllCombinations(2)\n",
    "        \n",
    "#         print(\"Testing on unseen data: \")\n",
    "#         test_mse(test_unseen, comb1, comb2)\n",
    "        best_performance(test_unseen)\n",
    "            \n",
    "    if \"test\" in targets: \n",
    "        \"\"\" runs all targets on sample data\"\"\"\n",
    "        print('tba')\n",
    "        # readfilerun for seen an unseen data\n",
    "       \n",
    "        #  main_eda(test_seen, **eda_config)\n",
    "#          print(\"EDA saved to outputs/eda/ folder\")\n",
    "        \n",
    "#         comb1 = getAllCombinations(1)\n",
    "#         comb2 = getAllCombinations(2)\n",
    "        \n",
    "#         print(\"Testing on seen data: \")\n",
    "#         test_mse(test_seen, comb1, comb2)\n",
    "#         best_performance(test_seen)\n",
    "        \n",
    "#         print(\"Testing on unseen data: \")\n",
    "#         test_mse(test_unseen, comb1, comb2)\n",
    "#         best_performance(test_unseen)\n",
    "        \n",
    "    if 'all' in targets: \n",
    "        # refer to test target\n",
    "        print('tba')\n",
    "        \n",
    "# if __name__ == '__main__':\n",
    "\n",
    "#     targets = sys.argv[1:]\n",
    "#     main(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f3a82d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = ['data', 'eda', 'train', 'inference', 'test', 'all']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9aa4587d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "time() missing 1 required positional argument: 'dataframe'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-288401193af8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ms1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# main(targets[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0ms2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mminutes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ms1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0ms2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminutes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: time() missing 1 required positional argument: 'dataframe'"
     ]
    }
   ],
   "source": [
    "s1 = time.time()\n",
    "# main(targets[0])\n",
    "s2 = time.time()\n",
    "minutes = (s1 - s2)/60\n",
    "print(minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bfe4097f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loss Performance sorted from highest to lowest metric: r2 \n",
      "\n",
      "                                                 feat     dt     rf     et  \\\n",
      "56  ['total_pkts_max', 'mean_tdelta', 'total_pkt_s...  0.245  0.536  0.519   \n",
      "49  ['mean_tdelta', 'total_pkts_max', 'pkt sum', '...  0.237  0.520  0.515   \n",
      "88  ['total_pkts_max', 'mean_tdelta', 'total_pkt_s...  0.236  0.549  0.531   \n",
      "19  ['mean_tdelta', 'total_pkts_max', '2->1Bytes',...  0.202  0.554  0.555   \n",
      "89  ['total_pkts_max', '2->1Bytes', 'number_ms', '...  0.199  0.556  0.552   \n",
      "\n",
      "      gbc  \n",
      "56  0.429  \n",
      "49  0.428  \n",
      "88  0.450  \n",
      "19  0.514  \n",
      "89  0.506   \n",
      "\n",
      "\n",
      "\n",
      "Latency Performance sorted from highest to lowest metric: r2 \n",
      "\n",
      "                                                feat2    dt2    rf2    et2  \\\n",
      "30                                ['time_spread_min'] -2.275 -1.819 -2.132   \n",
      "58  ['total_bytes', '2->1Pkts', 'pkt_ratio', 'time... -4.169 -1.837 -1.546   \n",
      "55  ['pkt_ratio', 'total_bytes', 'time_spread_min'... -4.384 -1.814 -1.416   \n",
      "59  ['2->1Pkts', 'pkt_ratio', 'time_spread_min', '... -4.384 -1.844 -1.462   \n",
      "60     ['pkt_ratio', 'time_spread_min', 'max_tdelta'] -4.898 -1.232 -1.308   \n",
      "\n",
      "     gbc2  \n",
      "30 -1.707  \n",
      "58 -2.880  \n",
      "55 -2.639  \n",
      "59 -2.552  \n",
      "60 -1.750   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "main(targets[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159e9c33",
   "metadata": {},
   "source": [
    "git add . |\n",
    "git commmit -m \"message\" |\n",
    "git pull origin main |\n",
    "git push |\n",
    "user, token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab445c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#listdir('data/raw/train_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f8068e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "label_col = 'latency'\n",
    "\n",
    "df = pd.read_csv(os.path.join(os.getcwd() , \"outputs\", 'combined_transform.csv'))\n",
    "\n",
    "indexcol = ['total_bytes','max_bytes','2->1Bytes','2->1Pkts','total_pkts', 'total_pkts_min', 'total_pkts_max', 'number_ms', 'pkt_ratio','time_spread', 'time_spread_min','time_spread_max','pkt sum','longest_seq', 'longest_seq_min', 'longest_seq_max','total_pkt_sizes','byte_ratio', 'mean_tdelta', 'max_tdelta']\n",
    "len(indexcol)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[[x for x in indexcol if x in df.columns]], df[label_col])\n",
    "# print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "etree = ExtraTreesRegressor(n_estimators=400, n_jobs=4)\n",
    "etreeft = etree.fit(X_train,y_train)\n",
    "\n",
    "y_pred3 = etree.predict(X_test)\n",
    "acc3= mean_squared_error(y_test, y_pred3)\n",
    "\n",
    "print(f'mse: {acc3}, r2: {etree.score(X_test, y_test)}')\n",
    "feat_imp = pd.Series(index=[x for x in indexcol if x in df.columns], \n",
    "          data=etree.feature_importances_).sort_values(ascending=False)\n",
    "feat_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a61cf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "label_col = 'loss'\n",
    "\n",
    "df = pd.read_csv(os.path.join(os.getcwd() , \"outputs\", 'combined_transform.csv'))\n",
    "\n",
    "indexcol = ['total_bytes','max_bytes','2->1Bytes','2->1Pkts','total_pkts', 'total_pkts_min', 'total_pkts_max', 'number_ms', 'pkt_ratio','time_spread', 'time_spread_min','time_spread_max','pkt sum','longest_seq', 'longest_seq_min', 'longest_seq_max','total_pkt_sizes','byte_ratio', 'mean_tdelta', 'max_tdelta']\n",
    "len(indexcol)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[[x for x in indexcol if x in df.columns]], df[label_col])\n",
    "# print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "etree = ExtraTreesRegressor(n_estimators=400, n_jobs=4)\n",
    "etreeft = etree.fit(X_train,y_train)\n",
    "\n",
    "y_pred3 = etree.predict(X_test)\n",
    "acc3= mean_squared_error(y_test, y_pred3)\n",
    "\n",
    "print(f'mse: {acc3}, r2: {etree.score(X_test, y_test)}')\n",
    "feat_imp = pd.Series(index=[x for x in indexcol if x in df.columns], \n",
    "          data=etree.feature_importances_).sort_values(ascending=False)\n",
    "feat_imp"
   ]
  },
  {
   "cell_type": "raw",
   "id": "79d30554",
   "metadata": {},
   "source": [
    "MAKING pipeline: , tst on data with change in loss later\n",
    "    \n",
    "    comb[some index]\n",
    "    \n",
    "    dt() - untrained\n",
    "    \n",
    "    dt( comb) - train, or grid search on it\n",
    "    \n",
    "    et() - \n",
    "    \n",
    "    plot them on top of eachother\n",
    "    \n",
    "    test(single dataset - aggregated over subset )# overserved or not\n",
    "    \n",
    "    plot the bytes, loss records (loss log), and expanded model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f16b215",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "path = os.path.join(os.getcwd() , \"outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f9419d",
   "metadata": {},
   "outputs": [],
   "source": [
    "comb1 = getAllCombinations(1)\n",
    "comb2 = getAllCombinations(2)\n",
    "comb1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cca963b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fname = 'labeled-from-data2_100-10000-true-100-10000.csv'\n",
    "genviz('seen', fname, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca742245",
   "metadata": {},
   "outputs": [],
   "source": [
    "newfname = 'combined_t.csv'\n",
    "s_t = pd.read_csv(os.path.join(os.getcwd() , \"outputs\", newfname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601e25b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# expanding pipeline for two predictors? mainly loss is impt, latency less so\n",
    "X, y = s_t[comb1[4]], s_t['loss']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                   random_state=0)\n",
    "pipe = Pipeline([('scaler', StandardScaler()), ('svc', GradientBoostingRegressor())])\n",
    " # The pipeline can be used as any other estimator\n",
    "# and avoids leaking the test set into the train set\n",
    "\n",
    "\n",
    "clf = GridSearchCV(GradientBoostingClassifier(), parameters,scoring=scoring,refit=False,cv=2, n_jobs=-1)\n",
    "\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "p = pipe.predict(X_test)\n",
    "mean_squared_error(y_test, p)\n",
    "#pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242447c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02dba4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_detailed_bytes(df, col='1->2Bytes', rollsec=10):\n",
    "    rollcolor = '#6c2b6d'\n",
    "    detailcolor = '#e98d6b'\n",
    "    \n",
    "    ax = plt.figure(figsize=(18,8))\n",
    "    df[col].plot(title=f'{col}/s Rate', color=detailcolor)\n",
    "    df[col].rolling(rollsec).mean().bfill().plot(color=rollcolor)\n",
    "    plt.axvline(x=180, color='r')\n",
    "    for i in df[df['event'] == 'drop'].index:\n",
    "        plt.axvline(x=i, color='y', alpha=.45)\n",
    "    custom_lines = [Line2D([0], [0], color=detailcolor, lw=2),\n",
    "        Line2D([0], [0], color=rollcolor, lw=2),\n",
    "        Line2D([0], [0], color='y', lw=2, alpha=0.45),\n",
    "        Line2D([0], [0], color='r', lw=2)]\n",
    "    plt.legend(custom_lines, \n",
    "               [f'{col} per Second', f'{col} per Second ({rollsec}s rolling avg)', 'Packet drop', '180s Mark'], \n",
    "               loc='upper right', framealpha=1);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
